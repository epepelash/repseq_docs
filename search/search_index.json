{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#mixcr-analyze","title":"MiXCR analyze","text":"<pre><code># Will be made executable with markdown-exec (although there should be other options)\n# Not ready yet :(\nimport os\nimport pandas as pd\nfrom IPython.display import Image, display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>REPSEQ_PATH = '/home/epepeliaeva/soft/repseq/'\n\nimport sys\n\nsys.path.append(REPSEQ_PATH)\nfrom repseq import io as repseqio\nfrom repseq import mixcr as mx\nfrom repseq import slurm\nfrom repseq import clonosets as cl\nfrom repseq import stats\nfrom repseq import clone_filter as clf\nfrom repseq import intersections\nfrom repseq import clustering\nfrom repseq import logo\nfrom repseq import vdjtools\n</code></pre> <p><pre><code>MIXCR = \"/projects/cdr3_software/bin/mixcr\"\n\nWORKING_DIR = \"/projects/cdr3_common/repseq_demo/\"\nMIXCR_DIR = os.path.join(WORKING_DIR, \"mixcr\")\n\nRAW_DATA_DIR = \"/projects/cdr3_ngs/2023/11_room555_MiSeq_13112023/\"\n\nSAMPLE_LIST_FILENAME = os.path.join(WORKING_DIR, \"sample_table.csv\")\nTABLE_REPORT_FILENAME = os.path.join(WORKING_DIR, \"table_report.csv\")\n\nos.makedirs(WORKING_DIR, exist_ok=True)\n</code></pre> <pre><code>WORKING_DIR = \"/projects/cdr3_common/repseq_demo/\"\nMIXCR_DIR = os.path.join(WORKING_DIR, \"mixcr\")\n\nRAW_DATA_DIR = \"/projects/cdr3_ngs/2023/11_room555_MiSeq_13112023/\"\n\nSAMPLE_LIST_FILENAME = os.path.join(WORKING_DIR, \"sample_table.csv\")\nTABLE_REPORT_FILENAME = os.path.join(WORKING_DIR, \"table_report.csv\")\n\nsample_df = repseqio.read_yaml_metadata(RAW_DATA_DIR)[[\"sample_id\", \"R1\", \"R2\"]].query('sample_id.str.contains(\"Rev05\")')\n\nmx.mixcr4_analyze_batch(sample_df=sample_df, \n                        output_folder = MIXCR_DIR, \n                        command_template=None,\n                        mixcr_path=MIXCR, \n                        memory=32, \n                        time_estimate=1.5)\n</code></pre></p> <pre><code>slurm.check_slurm_progress(os.path.join(MIXCR_DIR, \"mixcr_analyze_slurm_batch.log\"), loop=True)\n</code></pre> <pre><code>mx.show_report_images(MIXCR_DIR)\n</code></pre> <pre><code>proc_table = mx.get_processing_table(MIXCR_DIR)\nproc_table.to_csv(TABLE_REPORT_FILENAME, index=False)\nprint(f\"Report table saved to: {TABLE_REPORT_FILENAME}\")\nproc_table\n</code></pre>"},{"location":"filter/","title":"Clone filter","text":"<p>Clonoset filter. May be used to filter clonosets:     - by clone functionality     - randomly downsample them to particular number of reads of UMIs     - take top clonotypes by size (number of reads of UMIs) with or without random mixing</p> <p>Parameters:</p> Name Type Description Default <code>-</code> <code>name (str</code> <p>the name of the filter. Will be displayed in print</p> required <code>-</code> <code>functionality (str</code> <p>Possible values: - \"a\" - any (default). No clones are filtered out - \"f\" - only functional. Those, not having stop codons and      frame shifts in CDR3 regions, or having non-empty values in CDR3 amino-acid     sequence - \"n\" - only-nonfunctional - opposite to \"f\" - functional</p> required <code>-</code> <code>downsample (int</code> <p>the number of reads/UMIs to randomly downsample the clonoset to. default value 'None' - means not to apply downsampling</p> required <code>-</code> <code>top (int</code> <p>the number of top biggest by reads/UMIs clonotypes to take from the clonoset. default value 'None' - means not to apply top</p> required <code>-</code> <code>by_umi (bool</code> <p>default=False. Which column to take for clonotype count - reads or UMIs  (if UMI count column exists).</p> required <code>-</code> <code>mix_tails (bool</code> <p>default=False. Defines whether to randomly mix-up the order of clonotypes before sorting by size and taking the top clonotypes. Basically mix_tails=True mixes up  clonotypes with the same size in read or UMIs.</p> required <code>-</code> <code>count_threshold (int</code> <p>limits [0:100000], all clonotypes with count less than this value will be filtered out</p> required <code>-</code> <code>seed (any hashable type</code> <p>better to use int - seed for reproducibility of random events  (downsampling or top with mix-tails). Default=None.</p> required Source code in <code>repseq/clone_filter.py</code> <pre><code>class Filter:\n\n    \"\"\"\n    Clonoset filter.\n    May be used to filter clonosets:\n        - by clone functionality\n        - randomly downsample them to particular number of reads of UMIs\n        - take top clonotypes by size (number of reads of UMIs) with or without random mixing\n\n    Args:\n        - name (str): the name of the filter. Will be displayed in print\n        - functionality (str): Possible values:\n            - \"a\" - any (default). No clones are filtered out\n            - \"f\" - only functional. Those, not having stop codons and \n                frame shifts in CDR3 regions, or having non-empty values in CDR3 amino-acid\n                sequence\n            - \"n\" - only-nonfunctional - opposite to \"f\" - functional\n        - downsample (int): the number of reads/UMIs to randomly downsample the clonoset to.\n            default value 'None' - means not to apply downsampling\n        - top (int): the number of top biggest by reads/UMIs clonotypes to take from the clonoset.\n            default value 'None' - means not to apply top\n        - by_umi (bool): default=False. Which column to take for clonotype count - reads or UMIs \n            (if UMI count column exists).\n        - mix_tails (bool): default=False. Defines whether to randomly mix-up the order of clonotypes\n            before sorting by size and taking the top clonotypes. Basically mix_tails=True mixes up \n            clonotypes with the same size in read or UMIs.\n        - count_threshold (int): limits [0:100000], all clonotypes with count less than this value will\n            be filtered out\n        - seed (any hashable type): better to use int - seed for reproducibility of random events \n            (downsampling or top with mix-tails). Default=None.\n    \"\"\"\n\n    def __init__(self, name=\"default_filter\", functionality=\"a\", downsample=None,\n                 top=None, by_umi=False, mix_tails=False, count_threshold=None, \n                 unweight=False, seed=None, recount_fractions=True,\n                 white_list=[], black_list=[], pool_clonoset_by=\"\", convert=True, \n                 ignore_small_clonosets=False):\n        self.name = name\n        self.functionality = functionality\n        self.downsample_size = downsample\n        self.top = top\n        self.by_umi = by_umi\n        self.mix_tails = mix_tails\n        self.seed = seed\n        self.count_threshold = count_threshold\n        self.unweight = unweight\n        self.recount_fractions = recount_fractions\n        self.white_list = white_list\n        self.black_list = black_list\n        self.pool_by = pool_clonoset_by\n        self.convert = convert\n        self.ignore_small_clonosets = ignore_small_clonosets\n        self._check_input()\n\n    def spawn(self):\n        \"\"\"\n\n        Returns:\n            the copy of the filter. Necessary for parallel computing\n\n        \"\"\"\n        return Filter(name=self.name, functionality=self.functionality,\n                      downsample=self.downsample_size, top=self.top,\n                      by_umi=self.by_umi, mix_tails=self.mix_tails,\n                      count_threshold=self.count_threshold, seed=self.seed,\n                      unweight=self.unweight,\n                      recount_fractions=self.recount_fractions,\n                      white_list = self.white_list,\n                      black_list = self.black_list\n                      )\n\n    def apply(self, input_clonoset, colnames=None):\n        \"\"\"\n        Main method of the Filter object - application of it to a clonoset\n\n        Args:\n            input_clonoset (pd.DataFrame): clonoset in the form of Pandas DataFrame in\n                MiXCR(3 or 4+ version), VDJtools or Bioadaptive formats.\n            colnames (dict, optional): Dictionary of available specific column names.\n                Defaults to None - colnames imputed automatically.\n\n        Returns:\n            clonoset (pd.DataFrame): clonoset after converting to common (VDJtools-like)\n                format and applying functionality filtration and downsampling or taking top\n        \"\"\"\n\n        # copy clonoset for not changing the original one\n        clonoset = input_clonoset.copy()\n        if colnames is None:\n            colnames = get_column_names_from_clonoset(clonoset)\n\n        # create common columns: vdj-refPoints and VDJC-segments in common state\n        clonoset = self._make_common_columns(clonoset, colnames)\n        colnames = get_column_names_from_clonoset(clonoset)\n\n        # converting to common VDJtools-like format and obtaining new colnames\n        if self.convert:\n            clonoset = self._convert_clonoset(clonoset, colnames)\n            colnames = get_column_names_from_clonoset(clonoset)\n\n        # application of main filters\n        if self.functionality != \"a\":\n            clonoset = self._filter_by_functionality(clonoset, colnames)\n\n        clonoset = self._filter_by_count(clonoset, colnames)\n\n        clonoset = self._downsample(clonoset, colnames)\n        clonoset = self._get_top(clonoset, colnames)\n\n        if self.unweight:\n            clonoset = self._unweight(clonoset, colnames)\n        # the fraction columns need to be recounted after filtering, as they\n        # remain the same as in the original clonoset before filtration\n        if self.recount_fractions:\n            clonoset = self._recount_fractions_for_clonoset(clonoset, colnames)\n        if self.pool_by:\n            clonoset = self._pool_clonoset(clonoset, colnames)\n        if len(self.white_list) &gt; 0:\n            clonoset = self._filter_clonotypes(clonoset, list_type=\"white\")\n        if len(self.black_list) &gt; 0:\n            clonoset = self._filter_clonotypes(clonoset, list_type=\"black\")\n        return clonoset\n\n    def _convert_clonoset(self, clonoset, colnames):\n        # copy clonoset for not changing the original one\n        c_clonoset = clonoset.copy()\n\n        # basic column name in clonoset DF\n\n        count_column, fraction_column = decide_count_and_frac_columns(colnames, self.by_umi, suppress_warnings=True)\n\n        rename_dict = {count_column: \"count\",\n                       fraction_column: \"freq\",\n                       colnames[\"cdr3aa_column\"]: \"cdr3aa\",\n                       colnames[\"cdr3nt_column\"]: \"cdr3nt\",\n                       colnames[\"v_column\"]: \"v\",\n                       colnames[\"d_column\"]: \"d\",\n                       colnames[\"j_column\"]: \"j\"}\n        c_clonoset = c_clonoset.rename(columns=rename_dict)\n\n        result_columns = [\"count\", \"freq\"]\n        if \"cdr3nt\" in c_clonoset.columns:\n            result_columns.append(\"cdr3nt\")\n        result_columns += [\"cdr3aa\", \"v\"]\n        segment_borders_columns = [\"VEnd\", \"DStart\", \"DEnd\", \"JStart\"]\n\n\n\n\n        # In the case of MiXCR and Bioadaptive format the segment type columns\n        # usually show several segment variants with particular allele and score.\n        # Here we extract only the name of the best hit without allele ane score\n        c_clonoset[\"v\"] = c_clonoset[\"v\"].apply(lambda x: extract_segment(x))\n        if \"d\" in c_clonoset.columns:\n            c_clonoset[\"d\"] = c_clonoset[\"d\"].apply(lambda x: extract_segment(x))\n            result_columns.append(\"d\")\n        if \"j\" in c_clonoset.columns:\n            c_clonoset[\"j\"] = c_clonoset[\"j\"].apply(lambda x: extract_segment(x))\n            result_columns.append(\"j\")\n\n        # add the column for Constant segment if it exists in the original clonoset\n        if colnames[\"c_column\"] is not None:\n            c_clonoset = c_clonoset.rename(columns={colnames[\"c_column\"]: \"c\"})\n            c_clonoset[\"c\"] = c_clonoset[\"c\"].apply(lambda x: extract_segment(x))\n            result_columns += [\"c\"]\n\n        # obtain the borders of the segments within CDR3 region, if possible and add them to\n        # resulting clonoset\n        if \"refPoints\" in c_clonoset.columns:\n            c_clonoset[\"VEnd\"] = c_clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 11, minus=True))\n            c_clonoset[\"DStart\"] = c_clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 12, minus=False))\n            c_clonoset[\"DEnd\"] = c_clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 15, minus=True))\n            c_clonoset[\"JStart\"] = c_clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 16, minus=False))\n\n        result_columns += [col for col in segment_borders_columns if col in c_clonoset.columns]    \n\n        # save \"sample_id\" column if it is present in clonoset\n        if \"sample_id\" in c_clonoset.columns:\n            result_columns.append(\"sample_id\")\n        c_clonoset = c_clonoset.sort_values(by=\"count\", ascending=False).reset_index(drop=True)\n        return c_clonoset[result_columns]\n\n    def _make_common_columns(self, clonoset_in, colnames):\n        clonoset = clonoset_in.copy()\n\n        # treat refPoints\n        refpoints_columns = [\"VEnd\", \"DStart\", \"DEnd\", \"JStart\"]\n        if len(set(clonoset.columns).intersection(set(refpoints_columns))) &lt; 4: # check if not all the columns present\n            if \"refPoints\" in clonoset.columns: # if refPoints is present, create new columns\n                clonoset[\"VEnd\"] = clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 11, minus=True))\n                clonoset[\"DStart\"] = clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 12, minus=False))\n                clonoset[\"DEnd\"] = clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 15, minus=True))\n                clonoset[\"JStart\"] = clonoset[\"refPoints\"].apply(lambda x: extract_refpoint_position(x, 16, minus=False))\n\n        # treat v,d,j segments\n\n        # V\n        if \"v\" not in clonoset.columns:\n            if colnames[\"v_column\"] is not None:\n                clonoset[\"v\"] = clonoset[colnames[\"v_column\"]]\n        if \"v\" in clonoset.columns:\n            clonoset[\"v\"] = clonoset[\"v\"].apply(lambda x: extract_segment(x))\n\n        # D\n        if \"d\" not in clonoset.columns:\n            if colnames[\"d_column\"] is not None:\n                clonoset[\"d\"] = clonoset[colnames[\"d_column\"]]\n        if \"d\" in clonoset.columns:\n            clonoset[\"d\"] = clonoset[\"d\"].apply(lambda x: extract_segment(x))\n\n        # J\n        if \"j\" not in clonoset.columns:\n            if colnames[\"j_column\"] is not None:\n                clonoset[\"j\"] = clonoset[colnames[\"j_column\"]]\n        if \"j\" in clonoset.columns:\n            clonoset[\"j\"] = clonoset[\"j\"].apply(lambda x: extract_segment(x))\n\n        # C\n        if \"c\" not in clonoset.columns:\n            if colnames[\"c_column\"] is not None:\n                clonoset[\"c\"] = clonoset[colnames[\"c_column\"]]\n        if \"c\" in clonoset.columns:\n            clonoset[\"c\"] = clonoset[\"c\"].apply(lambda x: extract_segment(x))\n\n        if \"cdr3aa\" not in clonoset.columns:\n            if colnames[\"cdr3aa_column\"] is not None:\n                clonoset[\"cdr3aa\"] = clonoset[colnames[\"cdr3aa_column\"]]\n        if \"cdr3nt\" not in clonoset.columns:\n            if colnames[\"cdr3nt_column\"] is not None:\n                clonoset[\"cdr3nt\"] = clonoset[colnames[\"cdr3nt_column\"]]\n\n        return clonoset\n\n\n\n    def _unweight(self, clonoset_in, colnames):\n        clonoset = clonoset_in.copy()\n        clonoset[colnames[\"count_column\"]] = 1\n        return clonoset\n\n    def _recount_fractions_for_clonoset(self, clonoset_in, colnames):\n        if self.is_empty():\n            return clonoset_in\n        clonoset = clonoset_in.copy()\n\n        count_column = colnames[\"count_column\"]\n        fraction_column = colnames[\"fraction_column\"]\n        umi_column = colnames[\"umi_column\"]\n        umi_fraction_column = colnames[\"umi_fraction_column\"]\n\n        clonoset[fraction_column] = clonoset[count_column]/clonoset[count_column].sum()\n        if colnames[\"umi\"]:\n            clonoset[umi_fraction_column] = clonoset[umi_column]/clonoset[umi_column].sum()\n        return clonoset\n\n    def _filter_by_count(self, clonoset_in, colnames):\n        if self.count_threshold is None:\n            return clonoset_in\n        clonoset = clonoset_in.copy()\n        count_column = colnames[\"count_column\"]\n        clonoset = clonoset.loc[clonoset[count_column] &gt;= self.count_threshold]\n\n        return clonoset\n\n    def _check_input(self):\n\n        \"\"\"\n        Check if the object was created properly\n\n        Raises:\n            ValueError: in case of incorrect parameter values\n        \"\"\"\n        functionality_options = [\"a\", \"f\", \"n\"]\n        count_threshold_limits = [0, 100000]\n        if self.functionality not in functionality_options:\n            raise ValueError(f\"Incorrect value '{self.functionality}' for functionality. Possible values: {', '.join(functionality_options)}\")\n        if self.count_threshold is not None:\n            if not isinstance(self.count_threshold, int):\n                raise TypeError(\"Count threshold must be an 'int' or 'None'\")\n            if (self.count_threshold &lt; count_threshold_limits[0]\n                  or self.count_threshold &gt; count_threshold_limits[1]):\n                raise ValueError(f\"Incorrect value '{self.functionality}' for count_threshold. Possible values: {count_threshold_limits}\")                \n        if self.downsample_size is not None:\n            if not isinstance(self.downsample_size, int):\n                raise ValueError(f\"Incorrect value '{self.downsample_size}' for downsample_size. Only int or None possible\")\n            elif self.downsample_size &lt; 1:\n                raise ValueError(f\"Incorrect value '{self.downsample_size}' for downsample_size. Value too low\")\n        if self.top is not None:\n            if not isinstance(self.top, int):\n                raise ValueError(f\"Incorrect value '{self.top}' for top. Only int or None possible\")\n            elif self.top &lt; 1:\n                raise ValueError(f\"Incorrect value '{self.top}' for top. Value too low\")\n        if not isinstance(self.seed, Hashable):\n            raise ValueError(f\"Incorrect value '{self.seed}' for seed. Must be hashable\")\n        pool_by_options = [\"\", \"aa\", \"aaV\", \"aaVj\", \"nt\", \"ntV\", \"ntVJ\"]\n        if self.pool_by not in pool_by_options:\n            raise ValueError(f\"Incorrect value '{self.pool_by}' for clonoset pool. Possible values: {', '.join(pool_by_options)}\")\n\n    def _downsample(self, clonoset_in, colnames):\n        \"\"\"\n        Downsample clonoset.\n\n        This function takes the total number of reads or UMIs of the clonoset.\n        Then randomly samples the downsample_size from 0 to this total number of reads/UMIs. \n        This random sample is mapped to the clonotype sizes and \n        the new downsampled clonoset is created\n        \"\"\"\n\n        if self.downsample_size is None:\n            return clonoset_in\n\n        clonoset = clonoset_in.copy()\n        count_column = colnames[\"count_column\"]\n        total_count = int(clonoset[count_column].sum())\n\n        # raise ValueError if UMI/read count is less then downsample_size\n\n        if total_count &lt; self.downsample_size:\n            if self.ignore_small_clonosets:\n                return clonoset\n            else:\n                raise ValueError(f\"total count {total_count} is less than downsample size {self.downsample_size}\")\n        elif total_count == self.downsample_size:\n            return clonoset\n\n        # set seed if given and take the sample of total_count\n        if self.seed is not None:\n            random.seed(self.seed)\n        sample = sorted(random.sample(range(total_count), self.downsample_size))\n\n        # map the sample to the clone counts in the clonoset\n        curr_sum = 0\n        i = 0\n        new_counts_dict = {}\n        for index,r in clonoset.iterrows():\n            curr_sum+=r[count_column]\n            new_count = 0\n            if i == self.downsample_size:\n                break\n            while(sample[i]&lt;curr_sum):\n                new_count+=1\n                i+=1\n                if i == self.downsample_size:\n                    break\n            if new_count &gt; 0:\n                new_counts_dict[index]=new_count\n\n        # filter clonoset for missed clones and set new clone counts\n        (indices,counts) = zip(*new_counts_dict.items())\n        clonoset = clonoset.loc[clonoset.index.isin(indices)]\n        clonoset[count_column] = counts    \n        return clonoset.reset_index(drop=True)\n\n    def _get_top(self, clonoset_in, colnames):\n        \"\"\"\n        Takes top N biggest clones from the clonoset.\n\n        Mix-tails is recommended for use, because the order of the clonotypes\n        with equal count may not be independent from their other properties.\n        This option mixes up the order of all clonotypes in clonoset and then\n        sorts them by count in decreasing order, so that clonotypes with the same\n        count not have completely random order. Also use seed option for reproducibility\n        of the results.\n\n        Raises:\n            ValueError: if clone count is less then required top\n        \"\"\"\n\n        if self.top is None:\n            return clonoset_in\n\n        clonoset = clonoset_in.copy()\n        count_column = colnames[\"count_column\"]\n\n        #shuffle the order of clonotypes if required\n        if self.seed is not None:\n            random.seed(self.seed)\n        if self.mix_tails:\n            index_order = random.sample(list(clonoset.index), len(clonoset))\n            clonoset = clonoset.iloc[index_order] \n            clonoset = clonoset.sort_values(by=count_column, ascending=False)\n\n        if self.top &gt; len(clonoset):\n            if self.ignore_small_clonosets:\n                return clonoset\n            else:\n                raise ValueError(f\"Warning! Clonoset size - {len(clonoset)} - is less than required top - {self.top}\")\n\n        # take top\n        if self.top &gt; 0:\n            clonoset=clonoset.iloc[:self.top]\n\n        return clonoset.reset_index(drop=True)\n\n    def _filter_by_functionality(self, clonoset_in, colnames):\n        clonoset = clonoset_in.copy()\n\n        if self.functionality == \"f\":\n            clonoset = filter_by_functionality(clonoset, colnames=colnames, functional=True)\n        if self.functionality == \"n\":\n            clonoset = filter_by_functionality(clonoset, colnames=colnames, functional=False)\n\n        return clonoset.reset_index(drop=True)\n\n    def __str__(self):\n\n        functionality = {\"a\": \"any\",\n                         \"f\": \"only functional clones (no frameshifts and Stops)\",\n                         \"n\": \"only non-functional\"}\n        output  = f\"Filter name:\\t{self.name}\\n\"\n        output += f\"Functionality:\\t{functionality[self.functionality]}\\n\"\n        random = False\n        change_size = False\n        if self.functionality != \"a\":\n            change_size = True\n        if isinstance(self.count_threshold, int):\n            output += f\"Count threshold:\\t{self.count_threshold}\\n\"\n            change_size = True\n        if isinstance(self.downsample_size, int):\n            output += f\"Downsample size:\\t{self.downsample_size}\\n\"\n            random = True\n            change_size = True\n        if isinstance(self.top, int):\n            output += f\"Take top:\\t{self.top}\\n\"\n            change_size = True\n            if self.mix_tails:\n                random = True\n        if self.unweight:\n            output += f\"Clone size unweighted (all clone counts = 1)\"\n\n        if change_size:\n            if self.by_umi:\n                output += f\"Count by:\\t UMI (if exist)\\n\"\n            else:\n                output += f\"Count by:\\t reads/counts\\n\"\n        if random:\n            if isinstance(self.seed, int):\n                output += f\"Seed for random:\\t{self.seed}\\n\"\n            else:\n                output += f\"Seed for random:\\tunset\\n\"\n                output += f\"Warning: filter contains random events.\\nTo obtain reproducible results, set seed in calcutations or manually (random.seed(some_int))\\nprior to applying the filter.\\nNote only seed that is set as this object parameter will work for mix_tails\\n\"\n\n        return output\n\n    def _pool_clonoset(self, clonoset_in, colnames):\n        # copy clonoset and sort by clone counts and reset index for order\n        clonoset = clonoset_in.copy().sort_values(by=colnames[\"count_column\"], ascending=False).reset_index(drop=True)\n\n        # create list of pool columns\n        aa, check_v, check_j = overlap_type_to_flags(self.pool_by)\n        columns_for_pool = []\n        if aa:\n            columns_for_pool.append(colnames[\"cdr3aa_column\"])\n        else:\n            columns_for_pool.append(colnames[\"cdr3nt_column\"])\n        if check_v:\n            columns_for_pool.append(colnames[\"v_column\"])\n        if check_j:\n            columns_for_pool.append(colnames[\"j_column\"])\n\n        # create column combining all pool columns\n        clonoset[\"pool_id\"] = clonoset.apply(lambda x: \"|\".join([x[colname] for colname in columns_for_pool]), axis=1)\n\n        indices_to_retain = []\n\n        for pool_id in clonoset[\"pool_id\"].unique():\n            pool_clonoset = clonoset.loc[clonoset[\"pool_id\"] == pool_id]\n\n            # select the clone with biggest count - it will represent pooled clonotypes by\n            # columns other that count and freq\n            top_index = pool_clonoset.index[0]\n            indices_to_retain.append(top_index)\n\n            # sum counts and fractions for pooled clonotypes\n            clonoset.loc[top_index,colnames[\"count_column\"]] = pool_clonoset[colnames[\"count_column\"]].sum()\n            clonoset.loc[top_index,colnames[\"fraction_column\"]] = pool_clonoset[colnames[\"fraction_column\"]].sum()\n\n        # retain only rows with representative clonotypes and remove technical column\n        clonoset = clonoset.loc[indices_to_retain].drop(columns=[\"pool_id\"])\n\n        return clonoset\n\n    def _filter_clonotypes(self, clonoset_in, list_type):\n        if list_type == \"white\":\n            clonotypes_list = self.white_list\n        elif list_type == \"black\":\n            clonotypes_list = self.black_list\n        else:\n            raise ValueError(\"list_type must be 'white' or 'black'\")\n\n        clonoset = clonoset_in.copy()\n\n        clonoset[\"filter_pass\"] = clonoset.apply(lambda x: self._compare_clonoset_list_row_with_clonotype(x, clonotypes_list), axis=1)\n        if list_type == \"white\":\n            clonoset = clonoset[clonoset[\"filter_pass\"]].drop(columns=[\"filter_pass\"]).reset_index(drop=True)\n        else:\n            clonoset = clonoset[~clonoset[\"filter_pass\"]].drop(columns=[\"filter_pass\"]).reset_index(drop=True)\n        return clonoset\n\n\n# def convert_clonoset_to_clonotype_filter_list(clonoset_df, overlap_type=\"aaVJ\"):\n#     clonotypes_list = []\n#     aa, include_v, include_j = intersections.overlap_type_to_flags(overlap_type)\n#     for i,r in clonoset_df.iterrows():\n#         clonotype = []\n#         if aa:\n#             clonotype.append(row[\"cdr3aa\"])\n#         else:\n#             clonotype.append(row[\"cdr3nt\"])\n#         if include_v:\n#             clonotype.append(row[\"v\"])\n#         if include_j:\n#             clonotype.append(row[\"j\"])\n\n#         clonotype = tuple(clonotype)\n#         clonotypes_list.append(clonotype)\n#     return clonotypes_list\n\n    def _compare_clonoset_row_with_clonotype(self, row, clonotype):\n        c_len = len(clonotype)\n        if c_len == 1:\n            if row[\"cdr3aa\"] == clonotype[0]:\n                return True\n        elif c_len == 2:\n            if row[\"cdr3aa\"] == clonotype[0] and row[\"v\"] == clonotype[1]:\n                return True\n        elif c_len == 3:\n            if row[\"cdr3aa\"] == clonotype[0] and row[\"v\"] == clonotype[1] and row[\"j\"] == clonotype[2]:\n                return True\n        else:\n            # need to write better explanation for error\n            raise ValueError(\"clonotypes must contain from 1 to 3 values\")\n\n        return False\n\n    def _compare_clonoset_list_row_with_clonotype(self, row, clonotypes_list):\n        for clonotype in clonotypes_list:\n            if self._compare_clonoset_row_with_clonotype(row, clonotype):\n                return True\n        return False\n\n    def is_empty(self):\n        return self.functionality == \"a\" and self.downsample_size is None and self.top is None and self.count_threshold is None and not self.unweight\n\n    def _repr_html_(self):\n        \"\"\"\n        function for printing the Filter properties to Jupyter output\n        \"\"\"\n\n        functionality = {\"a\": \"any\",\n                         \"f\": \"only functional clones (no frameshifts and Stops)\",\n                         \"n\": \"only non-functional\"}\n        output  = f\"&lt;p&gt;Filter name: {self.name}&lt;/p&gt;\"\n        output += f\"&lt;p&gt;Functionality:\\t{functionality[self.functionality]}&lt;/p&gt;\"\n        random = False\n        change_size = False\n        if self.functionality != \"a\":\n            change_size = True\n        if isinstance(self.count_threshold, int):\n            output += f\"&lt;p&gt;Count threshold: {self.count_threshold}&lt;/p&gt;\"\n            change_size = True\n        if isinstance(self.downsample_size, int):\n            output += f\"&lt;p&gt;Downsample size: {self.downsample_size}&lt;/p&gt;\"\n            random = True\n            change_size = True\n        if isinstance(self.top, int):\n            output += f\"&lt;p&gt;Take top: {self.top}&lt;/p&gt;\"\n            change_size = True\n            if self.mix_tails:\n                random = True\n        if self.unweight:\n            output += f\"&lt;p&gt;Clone size unweighted: (all clone counts = 1)&lt;/p&gt;\"\n\n        if change_size:\n            if self.by_umi:\n                output += f\"&lt;p&gt;Count by:  UMI (if exist)&lt;/p&gt;\"\n            else:\n                output += f\"&lt;p&gt;Count by: reads/counts&lt;/p&gt;\"\n        if random:\n            if isinstance(self.seed, int):\n                output += f\"&lt;p&gt;Seed for random: {self.seed}&lt;/p&gt;\"\n            else:\n                output += f\"&lt;p&gt;Seed for random:\\tunset&lt;/p&gt;\"\n                output += f\"&lt;p&gt;Warning: filter contains random events. To obtain reproducible results, set seed in calcutations or manually (random.seed(some_int)) prior to applying the filter. Note only seed that is set as this object parameter will work for mix_tails&lt;/p&gt;\"\n\n        return output\n</code></pre>"},{"location":"filter/#clone_filter.Filter.apply","title":"<code>apply(input_clonoset, colnames=None)</code>","text":"<p>Main method of the Filter object - application of it to a clonoset</p> <p>Parameters:</p> Name Type Description Default <code>input_clonoset</code> <code>DataFrame</code> <p>clonoset in the form of Pandas DataFrame in MiXCR(3 or 4+ version), VDJtools or Bioadaptive formats.</p> required <code>colnames</code> <code>dict</code> <p>Dictionary of available specific column names. Defaults to None - colnames imputed automatically.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>clonoset</code> <code>DataFrame</code> <p>clonoset after converting to common (VDJtools-like) format and applying functionality filtration and downsampling or taking top</p> Source code in <code>repseq/clone_filter.py</code> <pre><code>def apply(self, input_clonoset, colnames=None):\n    \"\"\"\n    Main method of the Filter object - application of it to a clonoset\n\n    Args:\n        input_clonoset (pd.DataFrame): clonoset in the form of Pandas DataFrame in\n            MiXCR(3 or 4+ version), VDJtools or Bioadaptive formats.\n        colnames (dict, optional): Dictionary of available specific column names.\n            Defaults to None - colnames imputed automatically.\n\n    Returns:\n        clonoset (pd.DataFrame): clonoset after converting to common (VDJtools-like)\n            format and applying functionality filtration and downsampling or taking top\n    \"\"\"\n\n    # copy clonoset for not changing the original one\n    clonoset = input_clonoset.copy()\n    if colnames is None:\n        colnames = get_column_names_from_clonoset(clonoset)\n\n    # create common columns: vdj-refPoints and VDJC-segments in common state\n    clonoset = self._make_common_columns(clonoset, colnames)\n    colnames = get_column_names_from_clonoset(clonoset)\n\n    # converting to common VDJtools-like format and obtaining new colnames\n    if self.convert:\n        clonoset = self._convert_clonoset(clonoset, colnames)\n        colnames = get_column_names_from_clonoset(clonoset)\n\n    # application of main filters\n    if self.functionality != \"a\":\n        clonoset = self._filter_by_functionality(clonoset, colnames)\n\n    clonoset = self._filter_by_count(clonoset, colnames)\n\n    clonoset = self._downsample(clonoset, colnames)\n    clonoset = self._get_top(clonoset, colnames)\n\n    if self.unweight:\n        clonoset = self._unweight(clonoset, colnames)\n    # the fraction columns need to be recounted after filtering, as they\n    # remain the same as in the original clonoset before filtration\n    if self.recount_fractions:\n        clonoset = self._recount_fractions_for_clonoset(clonoset, colnames)\n    if self.pool_by:\n        clonoset = self._pool_clonoset(clonoset, colnames)\n    if len(self.white_list) &gt; 0:\n        clonoset = self._filter_clonotypes(clonoset, list_type=\"white\")\n    if len(self.black_list) &gt; 0:\n        clonoset = self._filter_clonotypes(clonoset, list_type=\"black\")\n    return clonoset\n</code></pre>"},{"location":"filter/#clone_filter.Filter.spawn","title":"<code>spawn()</code>","text":"<p>Returns:</p> Type Description <p>the copy of the filter. Necessary for parallel computing</p> Source code in <code>repseq/clone_filter.py</code> <pre><code>def spawn(self):\n    \"\"\"\n\n    Returns:\n        the copy of the filter. Necessary for parallel computing\n\n    \"\"\"\n    return Filter(name=self.name, functionality=self.functionality,\n                  downsample=self.downsample_size, top=self.top,\n                  by_umi=self.by_umi, mix_tails=self.mix_tails,\n                  count_threshold=self.count_threshold, seed=self.seed,\n                  unweight=self.unweight,\n                  recount_fractions=self.recount_fractions,\n                  white_list = self.white_list,\n                  black_list = self.black_list\n                  )\n</code></pre>"},{"location":"functions/","title":"Functions","text":""},{"location":"functions/#mixcr_1","title":"MiXCR","text":""},{"location":"functions/#mixcr.get_processing_table","title":"<code>get_processing_table(folder, show_offtarget=False, off_target_chain_threshold=0.01)</code>","text":"<p>Searches for clonosets in the the folder, extracts their sample_id's and shows main processing stats in a table format. By default does not show \"off-target\" clonosets -  those having less than 1% (default, may be overriden) of reads for the sample_id. For example, you have sequenced TRB sample, but there is found 0.5% (by read count)  of TRA chains for the same sample_id, then the clonoset will not be shown in the table. You can specify <code>show_offtarget=True</code> to display all found chains in the table or  outherwise set a higher value for <code>off_target_chain_threshold</code> (<code>0.01</code> by default).</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str or list</code> <p>folder or list of folders in which to look for clonosets and processing stats</p> required <code>show_offtarget</code> <code>bool</code> <p>add offtarget chains to the stats</p> <code>False</code> <code>off_target_chain_threshold</code> <code>float</code> <p>threshold for off-target chains</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>dataframe, containing <code>sample_id</code>, <code>extracted_chain</code> and  different processing stats columns. There may be several rows with the same  <code>sample_id</code>, with each found <code>extracted_chain</code></p> Source code in <code>repseq/mixcr.py</code> <pre><code>def get_processing_table(folder, show_offtarget=False, off_target_chain_threshold=0.01):\n    \"\"\"\n    Searches for clonosets in the the folder, extracts their sample_id's and shows main\n    processing stats in a table format. By default does not show \"off-target\" clonosets - \n    those having less than 1% (default, may be overriden) of reads for the sample_id.\n    For example, you have sequenced TRB sample, but there is found 0.5% (by read count) \n    of TRA chains for the same sample_id, then the clonoset will not be shown in the table.\n    You can specify `show_offtarget=True` to display all found chains in the table or \n    outherwise set a higher value for `off_target_chain_threshold` (`0.01` by default).\n\n    Args:\n        folder (str or list): folder or list of folders in which to look for clonosets and\n            processing stats\n        show_offtarget (bool): add offtarget chains to the stats\n        off_target_chain_threshold (float): threshold for off-target chains\n\n    Returns:\n        df (pd.DataFrame): dataframe, containing `sample_id`, `extracted_chain` and \n            different processing stats columns. There may be several rows with the same \n            `sample_id`, with each found `extracted_chain`\n    \"\"\"\n\n    if isinstance(folder, list):\n        tables = []\n        for f in folder:\n            table = get_processing_table(f, show_offtarget=show_offtarget)\n            tables.append(table)\n        return pd.concat(tables).sort_values(by=\"sample_id\").reset_index(drop=True)\n\n    results = []\n    clonosets = find_all_exported_clonosets_in_folder(folder, chain=None)\n\n    for i, r in clonosets.iterrows():\n        sample_id = r[\"sample_id\"]\n        chain = r[\"chain\"]\n        align_report = read_json_report(sample_id, folder, \"align\")\n\n        try:\n            refine_report = read_json_report(sample_id, folder, \"refine\")\n            umi = True\n        except FileNotFoundError:\n            umi = False\n\n        assemble_report = read_json_report(sample_id, folder, \"assemble\")\n\n        # print(sample_id, chain)\n        clonoset = read_clonoset(r.filename)\n        clonoset_f = filter_nonfunctional_clones(clonoset)\n\n        # align report\n        Rt=align_report[\"totalReadsProcessed\"]\n        Ru=align_report[\"totalReadsProcessed\"]-align_report[\"notAlignedReasons\"][\"NoBarcode\"]\n        Ru_pc = round(Ru/Rt*100, 2)\n        Ra=align_report[\"aligned\"]\n        Ra_pc = round(Ra/Rt*100, 2)\n        Roa = align_report[\"overlappedAligned\"]\n        Roa_pc = round(Roa/Ra*100, 2)\n\n        if umi:\n        #Ra2=refine_report[\"correctionReport\"][\"inputRecords\"] ##### differs from Ra, but D.Bolotin did not explain why\n\n            UMIa=refine_report[\"correctionReport\"][\"steps\"][0][\"inputDiversity\"]\n            UMIc=refine_report[\"correctionReport\"][\"steps\"][0][\"outputDiversity\"]\n            try:\n                UMIf=refine_report[\"correctionReport\"][\"filterReport\"][\"numberOfGroupsAccepted\"]\n            except TypeError:\n                UMIf=UMIc\n            Rf=refine_report[\"correctionReport\"][\"outputRecords\"]\n            try:\n                overseq_threshold = int(refine_report[\"correctionReport\"][\"filterReport\"][\"operatorReports\"][0][\"operatorReport\"][\"threshold\"])\n            except TypeError:\n                overseq_threshold = None\n            reads_per_umi = round(Rf/UMIf, 2)\n        else:\n            UMIa = np.nan\n            UMIc = np.nan\n            UMIf = np.nan\n            Rf = np.nan\n            overseq_threshold = np.nan\n            reads_per_umi = np.nan\n\n        Ct=assemble_report[\"clones\"]\n        Rcl=assemble_report[\"readsInClones\"]\n\n        Ctc=len(clonoset)\n        Rclc=int(clonoset.readCount.sum())\n\n        Cfunc=len(clonoset_f)\n        Rfunc=int(clonoset_f.readCount.sum())\n        if umi:\n            UMIcl=clonoset.uniqueMoleculeCount.sum()\n            UMIfunc=clonoset_f.uniqueMoleculeCount.sum()\n        else:\n            UMIcl=np.nan\n            UMIfunc=np.nan\n        if umi and overseq_threshold is None:\n            reads_per_umi = round(Rclc/UMIcl, 2)\n\n        results.append([sample_id, chain, Rt, Ru_pc, Ra_pc, Roa_pc, UMIa, UMIc, overseq_threshold, Rf, UMIf, reads_per_umi, Ct, Rcl, Ctc, Rclc, Cfunc, Rfunc, UMIcl, UMIfunc])\n    result_df = pd.DataFrame(results, columns=[\"sample_id\", \"extracted_chain\", \"reads_total\", \"reads_with_umi_pc\", \"reads_aligned_pc\", \"reads_overlapped_aln_pc\",\n                                               \"total_umi\", \"umi_after_correction\", \"overseq_threshold\", \"reads_after_filter\", \"umi_after_filter\",\n                                               \"reads_per_umi\", \"clones_total\", \"reads_in_clones_total\", \"clones\", \"reads_in_clones\", \"clones_func\", \"reads_in_func_clones\", \"umi_in_clones\", \"umi_in_func_clones\"])\n    if not show_offtarget:\n        result_df = result_df.loc[result_df.reads_in_clones/result_df.reads_in_clones_total &gt; off_target_chain_threshold]\n    return result_df.sort_values(by=\"sample_id\").reset_index(drop=True)\n</code></pre>"},{"location":"functions/#mixcr.mixcr4_analyze_batch","title":"<code>mixcr4_analyze_batch(sample_df, output_folder, command_template=None, mixcr_path='mixcr', memory=32, time_estimate=1.5, custom_tag_pattern_column=None)</code>","text":"<p>Function for batch runs of MiXCR software using SLURM. For each record in the given <code>sample_df</code> this function creates a SLURM-script in <code>~/temp/slurm</code> folder and adds them to SLURM-queue. All the <code>stdout</code> logs are also  put to <code>~/temp/slurm</code> folder. In case of troubles check the latest logs in this folder.  By default this function uses <code>mixcr analyze</code> command for MiLab Hum RNA TCR Kit (with UMI).  To change the command template use <code>command_template</code> parameter</p> <p>Parameters:</p> Name Type Description Default <code>sample_df</code> <code>DataFrame</code> <p>DataFrame, containing 'sample_id' column and  'R1' and 'R2' columns, containing paths (recommended full paths) to raw read files</p> required <code>output_folder</code> <code>str</code> <p>path to output folder</p> required <code>command_template</code> <code>str</code> <p>MiXCR command template  (default: 'mixcr analyze milab-human-rna-tcr-umi-multiplex -f r1 r2 output_prefix'). May be used as an example. Note that <code>mixcr analyze</code> and <code>r1 r2 output_prefix</code> are  \"magical\" parts of the template that should be kept as-is in the template, so change  only the part in-between these parts.</p> <code>None</code> <code>mixcr_path</code> <code>str</code> <p>path to MiXCR binary</p> <code>'mixcr'</code> <code>memory</code> <code>int</code> <p>required OOM in GB</p> <code>32</code> <code>time_estimate</code> <code>numeric</code> <p>time estimate in hours for the calculation. It is the limit for SLURM task</p> <code>1.5</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def mixcr4_analyze_batch(sample_df, output_folder, command_template=None,\n                         mixcr_path=\"mixcr\", memory=32, time_estimate=1.5, custom_tag_pattern_column=None):\n\n    \"\"\"\n    Function for batch runs of MiXCR software using SLURM.\n    For each record in the given `sample_df` this function creates a SLURM-script in\n    `~/temp/slurm` folder and adds them to SLURM-queue. All the `stdout` logs are also \n    put to `~/temp/slurm` folder. In case of troubles check the latest logs in this folder. \n    By default this function uses `mixcr analyze` command for MiLab Hum RNA TCR Kit (with UMI). \n    To change the command template use `command_template` parameter\n\n    Args:\n        sample_df (pd.DataFrame): DataFrame, containing 'sample_id' column and \n            'R1' and 'R2' columns, containing paths (recommended full paths) to raw read files\n        output_folder (str): path to output folder\n        command_template (str): MiXCR command template \n            (default: 'mixcr analyze milab-human-rna-tcr-umi-multiplex -f r1 r2 output_prefix').\n            May be used as an example. Note that `mixcr analyze` and `r1 r2 output_prefix` are \n            \"magical\" parts of the template that should be kept as-is in the template, so change \n            only the part in-between these parts.\n        mixcr_path (str): path to MiXCR binary\n        memory (int): required OOM in GB\n        time_estimate (numeric): time estimate in hours for the calculation. It\n            is the limit for SLURM task\n\n    Returns:\n        None\n    \"\"\"\n    max_memory = 1500\n    min_memory = 16\n\n    program_name=\"MIXCR4 Analyze Batch\"\n    samples_num = sample_df.shape[0]\n\n    # by default use the most popular preset for MiLaboratory Human TCR UMI MULTIPLEX Kit\n    default_command_template = \"mixcr analyze milab-human-rna-tcr-umi-multiplex -f r1 r2 output_prefix\"\n    if command_template is None:\n        command_template = default_command_template\n\n    # cut placeholders from command template\n    remove_list = [\"mixcr\", \"r1\", \"r2\", \"output_prefix\"]\n    command_template = ' '.join([w for w in command_template.split() if w not in remove_list])\n\n    # check input for custom tag pattern\n    custom_tag_pattern = False\n    if isinstance(custom_tag_pattern_column, str):\n        if custom_tag_pattern_column not in sample_df.columns:\n            raise ValueError(f\"Specified tag-pattern columns '{custom_tag_pattern_column}' is not present in sample_df\")\n        if \"--tag-pattern\" in command_template.split():\n            raise ValueError(f\"Please, remove '--tag-pattern' option from command_template, when you use custom tag-pattern\")\n        custom_tag_pattern = True\n\n    # Create output dir if does not exist\n    os.makedirs(output_folder, exist_ok=True)\n\n    # default mixcr analyze slurm parameters. They are quite excessive, works fine.\n    # time_estimate=1.5\n    cpus=40\n    if not isinstance(memory, int):\n        raise TypeError(\"memory parameter must be an integer\")\n    if memory &lt; min_memory:\n        print(f\"{memory} &lt; than limit ({min_memory}), using {min_memory} GB\")\n        memory = min_memory\n    if memory &gt; max_memory:\n        print(f\"{memory} &gt; than limit ({max_memory}), using {max_memory} GB\")\n        memory = max_memory\n\n\n    # create slurm batch file for progress tracking\n    slurm_batch_filename = os.path.join(output_folder, \"mixcr_analyze_slurm_batch.log\")\n    create_slurm_batch_file(slurm_batch_filename, program_name, samples_num)\n\n    # main cycle by samples\n    for i,r in sample_df.iterrows():\n        sample_id = r[\"sample_id\"]\n        r1 = r[\"R1\"]\n        r2 = r[\"R2\"]\n    #   output_prefix = os.path.join(output_folder, sample_id)\n        output_prefix = sample_id\n        if custom_tag_pattern:\n            tag_pattern = r[custom_tag_pattern_column]\n            command = f'{mixcr_path} -Xmx{memory}g {command_template} --tag-pattern \"{tag_pattern}\" {r1} {r2} {output_prefix}'\n        else:\n            command = f'{mixcr_path} -Xmx{memory}g {command_template} {r1} {r2} {output_prefix}'\n        command = f\"cd {output_folder}; \" + command\n        jobname = f\"mixcr_analyze_{sample_id}\"\n\n        # for batch task finish tracking:\n        command += f'; echo \"{jobname} finished\" &gt;&gt; {slurm_batch_filename}'\n\n        # create slurm script and add job to queue, print stdout of sbatch\n        stdout, stderr = run_slurm_command_from_jupyter(command, jobname, cpus, time_estimate, memory)\n        print(stdout, stderr)\n\n    print(f\"{samples_num} tasks added to slurm queue\\n\")\n    print(f'To see running progress bar run this function in the next jupyter cell:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\", loop=True)')\n    print(f'To see current progress:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\")')\n</code></pre>"},{"location":"functions/#mixcr.mixcr4_reports","title":"<code>mixcr4_reports(folder, mixcr_path='mixcr')</code>","text":"<p>runs <code>mixcr exportQc</code> commands - <code>align</code>, <code>chainUsage</code> and <code>tags</code> in a given folder  for all <code>.clns</code> filenames. <code>align</code> and <code>chainUsage</code> are run twice to create both  <code>svg</code> and <code>pdf</code> files.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>folder in which to run the <code>mixcr exportQc</code> commands</p> required <code>mixcr_path</code> <code>str</code> <p>path to MiXCR binary</p> <code>'mixcr'</code> <p>Returns:     None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def mixcr4_reports(folder, mixcr_path=\"mixcr\"):\n\n    \"\"\"\n    runs `mixcr exportQc` commands - `align`, `chainUsage` and `tags` in a given folder \n    for all `.clns` filenames. `align` and `chainUsage` are run twice to create both \n    `svg` and `pdf` files.\n\n    Args:\n        folder (str): folder in which to run the `mixcr exportQc` commands\n        mixcr_path (str): path to MiXCR binary\n    Returns:\n        None\n\n    \"\"\"\n\n\n    program_name=\"MIXCR4.3 Reports\"\n    time_estimate=1\n    cpus=40\n    memory=32\n\n    # clns_filenames = os.path.join(folder, \"*.clns\")\n    # align_filename = os.path.join(folder, \"alignQc.png\")\n    # chains_filename = os.path.join(folder, \"chainsQc.png\")\n    # tags_filename = os.path.join(folder, \"tagsQc.pdf\")\n    clns_filenames = \"*.clns\"\n    align_filename = \"alignQc.svg\"\n    chains_filename = \"chainsQc.svg\"\n    align_filename_pdf = \"alignQc.pdf\"\n    chains_filename_pdf = \"chainsQc.pdf\"\n    tags_filename = \"tagsQc.pdf\"\n    #tables_filename = os.path.join(folder, \"tables.tsv\")\n    #preproc_filename = os.path.join(folder, \"preproc_tables.tsv\")\n    #postanalysis_filename = os.path.join(folder, \"postanalysis.json\")\n\n\n\n    commands = {\"alignQc\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc align -f {clns_filenames} {align_filename}\",\n                \"chainUsage\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc chainUsage -f {clns_filenames} {chains_filename}\",\n                \"alignQcPDF\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc align -f {clns_filenames} {align_filename_pdf}\",\n                \"chainUsagePDF\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc chainUsage -f {clns_filenames} {chains_filename_pdf}\",\n                \"tagsQc\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc tags -f {clns_filenames} {tags_filename}\"#,\n                #\"postanalysis\": f\"{MIXCR} -Xmx32g postanalysis individual -f --default-downsampling none --default-weight-function umi --only-productive --tables {tables_filename} --preproc-tables {preproc_filename} {clns_filenames} {postanalysis_filename}\"\n               }\n\n\n    commands_num = len(commands)\n\n    slurm_batch_filename = os.path.join(folder, \"mixcr_reports_slurm_batch.log\")\n    create_slurm_batch_file(slurm_batch_filename, program_name, commands_num)\n\n    for jobname, command in commands.items():\n        command += f'; echo \"{jobname} finished\" &gt;&gt; {slurm_batch_filename}'\n        stdout, stderr = run_slurm_command_from_jupyter(command, jobname, cpus, time_estimate, memory)\n        print(stdout, stderr)\n</code></pre>"},{"location":"functions/#mixcr.mixcr_7genes_run_batch","title":"<code>mixcr_7genes_run_batch(sample_df, output_folder, mixcr_path='mixcr', memory=32, time_estimate=1.5)</code>","text":"<p>Function for batch runs of the MiXCR software using the SLURM <code>mixcr analyze</code> command and the <code>Human 7GENES DNA Multiplex</code> MiXCR built-in preset.  Incomplete rearrangements obtained by this kit are also included. For each incomplete rearrangement, unaligned reads from the previous  step are iteratively processed. Each output is stored in a subdirectory named after the corresponding rearrangement. For each record in the given <code>sample_df</code>, this function creates a SLURM script in the <code>~/temp/slurm</code> folder and adds it to the SLURM queue.  All <code>stdout</code> logs are also saved to the <code>~/temp/slurm</code> folder. In case of troubles, check the latest logs in this folder. </p> <p>Parameters:</p> Name Type Description Default <code>sample_df</code> <code>DataFrame</code> <p>DataFrame containing a 'sample_id' column and  'R1' and 'R2' columns containing paths (recommended full paths) to raw read files.</p> required <code>output_folder</code> <code>str</code> <p>Path to the output folder.</p> required <code>mixcr_path</code> <code>str</code> <p>Path to the MiXCR binary.</p> <code>'mixcr'</code> <code>memory</code> <code>int</code> <p>Required OOM in GB.</p> <code>32</code> <code>time_estimate</code> <code>numeric</code> <p>Time estimate in hours for the calculation; it  is the limit for the SLURM task.</p> <code>1.5</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def mixcr_7genes_run_batch(sample_df, output_folder, mixcr_path=\"mixcr\", memory=32, time_estimate=1.5):\n    \"\"\"\n    Function for batch runs of the MiXCR software using the SLURM `mixcr analyze` command and the `Human 7GENES DNA Multiplex` MiXCR built-in preset. \n    Incomplete rearrangements obtained by this kit are also included. For each incomplete rearrangement, unaligned reads from the previous \n    step are iteratively processed. Each output is stored in a subdirectory named after the corresponding rearrangement.\n    For each record in the given `sample_df`, this function creates a SLURM script in the `~/temp/slurm` folder and adds it to the SLURM queue. \n    All `stdout` logs are also saved to the `~/temp/slurm` folder. In case of troubles, check the latest logs in this folder. \n\n    Args:\n        sample_df (pd.DataFrame): DataFrame containing a 'sample_id' column and \n            'R1' and 'R2' columns containing paths (recommended full paths) to raw read files.\n        output_folder (str): Path to the output folder.\n        mixcr_path (str): Path to the MiXCR binary.\n        memory (int): Required OOM in GB.\n        time_estimate (numeric): Time estimate in hours for the calculation; it \n            is the limit for the SLURM task.\n\n    Returns:\n        None\n    \"\"\"\n    # default mixcr analyze slurm parameters. They are quite excessive, works fine.\n    max_memory = 1500\n    min_memory = 16\n    cpus=40\n\n    program_name=\"MIXCR4 Analyze 7genes Batch\"\n    samples_num = sample_df.shape[0]\n\n    # Create output dir if does not exist\n    os.makedirs(output_folder, exist_ok=True)\n\n\n    if not isinstance(memory, int):\n        raise TypeError(\"memory parameter must be an integer\")\n    if memory &lt; min_memory:\n        print(f\"{memory} &lt; than limit ({min_memory}), using {min_memory} GB\")\n        memory = min_memory\n    if memory &gt; max_memory:\n        print(f\"{memory} &gt; than limit ({max_memory}), using {max_memory} GB\")\n        memory = max_memory\n\n    # create slurm batch file for progress tracking\n    slurm_batch_filename = os.path.join(output_folder, \"mixcr_analyze_slurm_batch.log\")\n    create_slurm_batch_file(slurm_batch_filename, program_name, samples_num)\n\n    list_of_incomplete_rearrangements = [\"DJ_TRB\", \"VDD_TRD\", \"DDJ_TRD\", \"DD_TRD\", \"DJ_IGH\", \"VKDE_IGK\", \"CINTRON_KDE_IGK\"]\n\n    # main cycle by samples\n    for i,r in sample_df.iterrows():\n        sample_id = r[\"sample_id\"]\n        r1 = r[\"R1\"]\n        r2 = r[\"R2\"]\n        output_prefix = sample_id\n\n        R1na = f\"{sample_id}_R1_not_aligned.fastq.gz\"\n        R2na = f\"{sample_id}_R2_not_aligned.fastq.gz\"\n\n        commands = [f\"cd {output_folder}\"]\n\n        first_command = f'{mixcr_path} -Xmx{memory}g analyze milab-human-dna-xcr-7genes-multiplex -f --not-aligned-R1 {R1na} --not-aligned-R2 {R2na} {r1} {r2} {output_prefix}'\n        commands.append(first_command)\n\n        for rearrangement in list_of_incomplete_rearrangements:\n\n            # swap r and Rna so we would not implement copy of R_na\n            r1, R1na = R1na, r1\n            r2, R2na = R2na, r2\n\n            output_prefix = os.path.join(rearrangement, sample_id)\n\n            R1na = f\"{output_prefix}_R1_not_aligned.fastq.gz\"\n            R2na = f\"{output_prefix}_R2_not_aligned.fastq.gz\"\n\n            i_r_command = f'{mixcr_path} -Xmx{memory}g analyze generic-amplicon -f --species hs --library {rearrangement} --dna --floating-left-alignment-boundary --floating-right-alignment-boundary J -MexportClones.splitFilesBy=[] --not-aligned-R1 {R1na} --not-aligned-R2 {R2na} {r1} {r2} {output_prefix}'\n            commands.append(i_r_command)\n\n        jobname = f\"mixcr_analyze_{sample_id}\"\n\n        # for batch task finish tracking:\n        commands.append(f'echo \"{jobname} finished\" &gt;&gt; {slurm_batch_filename}')\n\n        # join commands by &amp;&amp; so that next command runs if previous was finished without error and add new lines to the script\n        command = \" &amp;&amp; \\\\ \\n\".join(commands)\n\n        # create slurm script and add job to queue, print stdout of sbatch\n        stdout, stderr = run_slurm_command_from_jupyter(command, jobname, cpus, time_estimate, memory)\n        print(stdout, stderr)\n        # print(command)\n    print(f\"{samples_num} tasks added to slurm queue\\n\")\n    print(f'To see running progress bar run this function in the next jupyter cell:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\", loop=True)')\n    print(f'To see current progress:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\")')\n</code></pre>"},{"location":"functions/#mixcr.show_report_images","title":"<code>show_report_images(folder)</code>","text":"<p>This function displays QC images <code>alignQc.svg</code> and <code>chainsQc.svg</code> in Jupyter Notebook. This pictures may be generated by <code>mixcr4_reports</code> function. In case there are no <code>.svg</code> images, the <code>.png</code> images are shown.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>folder in which to look for QC images.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def show_report_images(folder):\n    \"\"\"\n    This function displays QC images `alignQc.svg` and `chainsQc.svg` in Jupyter Notebook.\n    This pictures may be generated by `mixcr4_reports` function.\n    In case there are no `.svg` images, the `.png` images are shown.\n\n    Args:\n        folder (str): folder in which to look for QC images.\n\n    Returns:\n        None\n\n    \"\"\"\n\n    svg_align_filename = os.path.join(folder, \"alignQc.svg\")\n    svg_chain_filename = os.path.join(folder, \"chainsQc.svg\")\n    png_align_filename = os.path.join(folder, \"alignQc.png\")\n    png_chain_filename = os.path.join(folder, \"chainsQc.png\")\n\n    if os.path.exists(svg_align_filename):\n        print(svg_align_filename)\n        display(SVG(filename=svg_align_filename))\n    elif os.path.exists(png_align_filename):\n        print(png_align_filename)\n        display(Image(filename=png_align_filename))\n    else:\n        print(\"No alignQc image found (svg or png)\")\n\n    if os.path.exists(svg_chain_filename):\n        print(svg_chain_filename)\n        display(SVG(filename=svg_chain_filename))\n    elif os.path.exists(png_chain_filename):\n        print(png_chain_filename)\n        display(Image(filename=png_chain_filename))\n    else:\n        print(\"No chainQc image found (svg or png)\")\n</code></pre>"},{"location":"functions/#hhh","title":"hhh","text":"<p>:::</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"mixcr/","title":"MiXCR4 functions for batch analysis in Jupyter. Uses SLURM on Aldan3 server","text":""},{"location":"mixcr/#mixcr4_analyze_batch","title":"mixcr4_analyze_batch","text":"<p>Function for batch runs of MiXCR software using SLURM. For each record in the given <code>sample_df</code> this function creates a SLURM-script in <code>~/temp/slurm</code> folder and adds them to SLURM-queue. All the <code>stdout</code> logs are also  put to <code>~/temp/slurm</code> folder. In case of troubles check the latest logs in this folder.  By default this function uses <code>mixcr analyze</code> command for MiLab Hum RNA TCR Kit (with UMI).  To change the command template use <code>command_template</code> parameter</p> <p>Parameters:</p> Name Type Description Default <code>sample_df</code> <code>DataFrame</code> <p>DataFrame, containing 'sample_id' column and  'R1' and 'R2' columns, containing paths (recommended full paths) to raw read files</p> required <code>output_folder</code> <code>str</code> <p>path to output folder</p> required <code>command_template</code> <code>str</code> <p>MiXCR command template  (default: 'mixcr analyze milab-human-rna-tcr-umi-multiplex -f r1 r2 output_prefix'). May be used as an example. Note that <code>mixcr analyze</code> and <code>r1 r2 output_prefix</code> are  \"magical\" parts of the template that should be kept as-is in the template, so change  only the part in-between these parts.</p> <code>None</code> <code>mixcr_path</code> <code>str</code> <p>path to MiXCR binary</p> <code>'mixcr'</code> <code>memory</code> <code>int</code> <p>required OOM in GB</p> <code>32</code> <code>time_estimate</code> <code>numeric</code> <p>time estimate in hours for the calculation. It is the limit for SLURM task</p> <code>1.5</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def mixcr4_analyze_batch(sample_df, output_folder, command_template=None,\n                         mixcr_path=\"mixcr\", memory=32, time_estimate=1.5, custom_tag_pattern_column=None):\n\n    \"\"\"\n    Function for batch runs of MiXCR software using SLURM.\n    For each record in the given `sample_df` this function creates a SLURM-script in\n    `~/temp/slurm` folder and adds them to SLURM-queue. All the `stdout` logs are also \n    put to `~/temp/slurm` folder. In case of troubles check the latest logs in this folder. \n    By default this function uses `mixcr analyze` command for MiLab Hum RNA TCR Kit (with UMI). \n    To change the command template use `command_template` parameter\n\n    Args:\n        sample_df (pd.DataFrame): DataFrame, containing 'sample_id' column and \n            'R1' and 'R2' columns, containing paths (recommended full paths) to raw read files\n        output_folder (str): path to output folder\n        command_template (str): MiXCR command template \n            (default: 'mixcr analyze milab-human-rna-tcr-umi-multiplex -f r1 r2 output_prefix').\n            May be used as an example. Note that `mixcr analyze` and `r1 r2 output_prefix` are \n            \"magical\" parts of the template that should be kept as-is in the template, so change \n            only the part in-between these parts.\n        mixcr_path (str): path to MiXCR binary\n        memory (int): required OOM in GB\n        time_estimate (numeric): time estimate in hours for the calculation. It\n            is the limit for SLURM task\n\n    Returns:\n        None\n    \"\"\"\n    max_memory = 1500\n    min_memory = 16\n\n    program_name=\"MIXCR4 Analyze Batch\"\n    samples_num = sample_df.shape[0]\n\n    # by default use the most popular preset for MiLaboratory Human TCR UMI MULTIPLEX Kit\n    default_command_template = \"mixcr analyze milab-human-rna-tcr-umi-multiplex -f r1 r2 output_prefix\"\n    if command_template is None:\n        command_template = default_command_template\n\n    # cut placeholders from command template\n    remove_list = [\"mixcr\", \"r1\", \"r2\", \"output_prefix\"]\n    command_template = ' '.join([w for w in command_template.split() if w not in remove_list])\n\n    # check input for custom tag pattern\n    custom_tag_pattern = False\n    if isinstance(custom_tag_pattern_column, str):\n        if custom_tag_pattern_column not in sample_df.columns:\n            raise ValueError(f\"Specified tag-pattern columns '{custom_tag_pattern_column}' is not present in sample_df\")\n        if \"--tag-pattern\" in command_template.split():\n            raise ValueError(f\"Please, remove '--tag-pattern' option from command_template, when you use custom tag-pattern\")\n        custom_tag_pattern = True\n\n    # Create output dir if does not exist\n    os.makedirs(output_folder, exist_ok=True)\n\n    # default mixcr analyze slurm parameters. They are quite excessive, works fine.\n    # time_estimate=1.5\n    cpus=40\n    if not isinstance(memory, int):\n        raise TypeError(\"memory parameter must be an integer\")\n    if memory &lt; min_memory:\n        print(f\"{memory} &lt; than limit ({min_memory}), using {min_memory} GB\")\n        memory = min_memory\n    if memory &gt; max_memory:\n        print(f\"{memory} &gt; than limit ({max_memory}), using {max_memory} GB\")\n        memory = max_memory\n\n\n    # create slurm batch file for progress tracking\n    slurm_batch_filename = os.path.join(output_folder, \"mixcr_analyze_slurm_batch.log\")\n    create_slurm_batch_file(slurm_batch_filename, program_name, samples_num)\n\n    # main cycle by samples\n    for i,r in sample_df.iterrows():\n        sample_id = r[\"sample_id\"]\n        r1 = r[\"R1\"]\n        r2 = r[\"R2\"]\n    #   output_prefix = os.path.join(output_folder, sample_id)\n        output_prefix = sample_id\n        if custom_tag_pattern:\n            tag_pattern = r[custom_tag_pattern_column]\n            command = f'{mixcr_path} -Xmx{memory}g {command_template} --tag-pattern \"{tag_pattern}\" {r1} {r2} {output_prefix}'\n        else:\n            command = f'{mixcr_path} -Xmx{memory}g {command_template} {r1} {r2} {output_prefix}'\n        command = f\"cd {output_folder}; \" + command\n        jobname = f\"mixcr_analyze_{sample_id}\"\n\n        # for batch task finish tracking:\n        command += f'; echo \"{jobname} finished\" &gt;&gt; {slurm_batch_filename}'\n\n        # create slurm script and add job to queue, print stdout of sbatch\n        stdout, stderr = run_slurm_command_from_jupyter(command, jobname, cpus, time_estimate, memory)\n        print(stdout, stderr)\n\n    print(f\"{samples_num} tasks added to slurm queue\\n\")\n    print(f'To see running progress bar run this function in the next jupyter cell:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\", loop=True)')\n    print(f'To see current progress:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\")')\n</code></pre>"},{"location":"mixcr/#mixcr_7genes_run_batch","title":"mixcr_7genes_run_batch","text":"<p>Function for batch runs of the MiXCR software using the SLURM <code>mixcr analyze</code> command and the <code>Human 7GENES DNA Multiplex</code> MiXCR built-in preset.  Incomplete rearrangements obtained by this kit are also included. For each incomplete rearrangement, unaligned reads from the previous  step are iteratively processed. Each output is stored in a subdirectory named after the corresponding rearrangement. For each record in the given <code>sample_df</code>, this function creates a SLURM script in the <code>~/temp/slurm</code> folder and adds it to the SLURM queue.  All <code>stdout</code> logs are also saved to the <code>~/temp/slurm</code> folder. In case of troubles, check the latest logs in this folder. </p> <p>Parameters:</p> Name Type Description Default <code>sample_df</code> <code>DataFrame</code> <p>DataFrame containing a 'sample_id' column and  'R1' and 'R2' columns containing paths (recommended full paths) to raw read files.</p> required <code>output_folder</code> <code>str</code> <p>Path to the output folder.</p> required <code>mixcr_path</code> <code>str</code> <p>Path to the MiXCR binary.</p> <code>'mixcr'</code> <code>memory</code> <code>int</code> <p>Required OOM in GB.</p> <code>32</code> <code>time_estimate</code> <code>numeric</code> <p>Time estimate in hours for the calculation; it  is the limit for the SLURM task.</p> <code>1.5</code> <p>Returns:</p> Type Description <p>None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def mixcr_7genes_run_batch(sample_df, output_folder, mixcr_path=\"mixcr\", memory=32, time_estimate=1.5):\n    \"\"\"\n    Function for batch runs of the MiXCR software using the SLURM `mixcr analyze` command and the `Human 7GENES DNA Multiplex` MiXCR built-in preset. \n    Incomplete rearrangements obtained by this kit are also included. For each incomplete rearrangement, unaligned reads from the previous \n    step are iteratively processed. Each output is stored in a subdirectory named after the corresponding rearrangement.\n    For each record in the given `sample_df`, this function creates a SLURM script in the `~/temp/slurm` folder and adds it to the SLURM queue. \n    All `stdout` logs are also saved to the `~/temp/slurm` folder. In case of troubles, check the latest logs in this folder. \n\n    Args:\n        sample_df (pd.DataFrame): DataFrame containing a 'sample_id' column and \n            'R1' and 'R2' columns containing paths (recommended full paths) to raw read files.\n        output_folder (str): Path to the output folder.\n        mixcr_path (str): Path to the MiXCR binary.\n        memory (int): Required OOM in GB.\n        time_estimate (numeric): Time estimate in hours for the calculation; it \n            is the limit for the SLURM task.\n\n    Returns:\n        None\n    \"\"\"\n    # default mixcr analyze slurm parameters. They are quite excessive, works fine.\n    max_memory = 1500\n    min_memory = 16\n    cpus=40\n\n    program_name=\"MIXCR4 Analyze 7genes Batch\"\n    samples_num = sample_df.shape[0]\n\n    # Create output dir if does not exist\n    os.makedirs(output_folder, exist_ok=True)\n\n\n    if not isinstance(memory, int):\n        raise TypeError(\"memory parameter must be an integer\")\n    if memory &lt; min_memory:\n        print(f\"{memory} &lt; than limit ({min_memory}), using {min_memory} GB\")\n        memory = min_memory\n    if memory &gt; max_memory:\n        print(f\"{memory} &gt; than limit ({max_memory}), using {max_memory} GB\")\n        memory = max_memory\n\n    # create slurm batch file for progress tracking\n    slurm_batch_filename = os.path.join(output_folder, \"mixcr_analyze_slurm_batch.log\")\n    create_slurm_batch_file(slurm_batch_filename, program_name, samples_num)\n\n    list_of_incomplete_rearrangements = [\"DJ_TRB\", \"VDD_TRD\", \"DDJ_TRD\", \"DD_TRD\", \"DJ_IGH\", \"VKDE_IGK\", \"CINTRON_KDE_IGK\"]\n\n    # main cycle by samples\n    for i,r in sample_df.iterrows():\n        sample_id = r[\"sample_id\"]\n        r1 = r[\"R1\"]\n        r2 = r[\"R2\"]\n        output_prefix = sample_id\n\n        R1na = f\"{sample_id}_R1_not_aligned.fastq.gz\"\n        R2na = f\"{sample_id}_R2_not_aligned.fastq.gz\"\n\n        commands = [f\"cd {output_folder}\"]\n\n        first_command = f'{mixcr_path} -Xmx{memory}g analyze milab-human-dna-xcr-7genes-multiplex -f --not-aligned-R1 {R1na} --not-aligned-R2 {R2na} {r1} {r2} {output_prefix}'\n        commands.append(first_command)\n\n        for rearrangement in list_of_incomplete_rearrangements:\n\n            # swap r and Rna so we would not implement copy of R_na\n            r1, R1na = R1na, r1\n            r2, R2na = R2na, r2\n\n            output_prefix = os.path.join(rearrangement, sample_id)\n\n            R1na = f\"{output_prefix}_R1_not_aligned.fastq.gz\"\n            R2na = f\"{output_prefix}_R2_not_aligned.fastq.gz\"\n\n            i_r_command = f'{mixcr_path} -Xmx{memory}g analyze generic-amplicon -f --species hs --library {rearrangement} --dna --floating-left-alignment-boundary --floating-right-alignment-boundary J -MexportClones.splitFilesBy=[] --not-aligned-R1 {R1na} --not-aligned-R2 {R2na} {r1} {r2} {output_prefix}'\n            commands.append(i_r_command)\n\n        jobname = f\"mixcr_analyze_{sample_id}\"\n\n        # for batch task finish tracking:\n        commands.append(f'echo \"{jobname} finished\" &gt;&gt; {slurm_batch_filename}')\n\n        # join commands by &amp;&amp; so that next command runs if previous was finished without error and add new lines to the script\n        command = \" &amp;&amp; \\\\ \\n\".join(commands)\n\n        # create slurm script and add job to queue, print stdout of sbatch\n        stdout, stderr = run_slurm_command_from_jupyter(command, jobname, cpus, time_estimate, memory)\n        print(stdout, stderr)\n        # print(command)\n    print(f\"{samples_num} tasks added to slurm queue\\n\")\n    print(f'To see running progress bar run this function in the next jupyter cell:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\", loop=True)')\n    print(f'To see current progress:\\nslurm.check_slurm_progress(\"{slurm_batch_filename}\")')\n</code></pre>"},{"location":"mixcr/#mixcr4_reports","title":"mixcr4_reports","text":"<p>runs <code>mixcr exportQc</code> commands - <code>align</code>, <code>chainUsage</code> and <code>tags</code> in a given folder  for all <code>.clns</code> filenames. <code>align</code> and <code>chainUsage</code> are run twice to create both  <code>svg</code> and <code>pdf</code> files.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>folder in which to run the <code>mixcr exportQc</code> commands</p> required <code>mixcr_path</code> <code>str</code> <p>path to MiXCR binary</p> <code>'mixcr'</code> <p>Returns:     None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def mixcr4_reports(folder, mixcr_path=\"mixcr\"):\n\n    \"\"\"\n    runs `mixcr exportQc` commands - `align`, `chainUsage` and `tags` in a given folder \n    for all `.clns` filenames. `align` and `chainUsage` are run twice to create both \n    `svg` and `pdf` files.\n\n    Args:\n        folder (str): folder in which to run the `mixcr exportQc` commands\n        mixcr_path (str): path to MiXCR binary\n    Returns:\n        None\n\n    \"\"\"\n\n\n    program_name=\"MIXCR4.3 Reports\"\n    time_estimate=1\n    cpus=40\n    memory=32\n\n    # clns_filenames = os.path.join(folder, \"*.clns\")\n    # align_filename = os.path.join(folder, \"alignQc.png\")\n    # chains_filename = os.path.join(folder, \"chainsQc.png\")\n    # tags_filename = os.path.join(folder, \"tagsQc.pdf\")\n    clns_filenames = \"*.clns\"\n    align_filename = \"alignQc.svg\"\n    chains_filename = \"chainsQc.svg\"\n    align_filename_pdf = \"alignQc.pdf\"\n    chains_filename_pdf = \"chainsQc.pdf\"\n    tags_filename = \"tagsQc.pdf\"\n    #tables_filename = os.path.join(folder, \"tables.tsv\")\n    #preproc_filename = os.path.join(folder, \"preproc_tables.tsv\")\n    #postanalysis_filename = os.path.join(folder, \"postanalysis.json\")\n\n\n\n    commands = {\"alignQc\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc align -f {clns_filenames} {align_filename}\",\n                \"chainUsage\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc chainUsage -f {clns_filenames} {chains_filename}\",\n                \"alignQcPDF\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc align -f {clns_filenames} {align_filename_pdf}\",\n                \"chainUsagePDF\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc chainUsage -f {clns_filenames} {chains_filename_pdf}\",\n                \"tagsQc\": f\"cd {folder}; {mixcr_path} -Xmx32g exportQc tags -f {clns_filenames} {tags_filename}\"#,\n                #\"postanalysis\": f\"{MIXCR} -Xmx32g postanalysis individual -f --default-downsampling none --default-weight-function umi --only-productive --tables {tables_filename} --preproc-tables {preproc_filename} {clns_filenames} {postanalysis_filename}\"\n               }\n\n\n    commands_num = len(commands)\n\n    slurm_batch_filename = os.path.join(folder, \"mixcr_reports_slurm_batch.log\")\n    create_slurm_batch_file(slurm_batch_filename, program_name, commands_num)\n\n    for jobname, command in commands.items():\n        command += f'; echo \"{jobname} finished\" &gt;&gt; {slurm_batch_filename}'\n        stdout, stderr = run_slurm_command_from_jupyter(command, jobname, cpus, time_estimate, memory)\n        print(stdout, stderr)\n</code></pre>"},{"location":"mixcr/#get_processing_table","title":"get_processing_table","text":"<p>Searches for clonosets in the the folder, extracts their sample_id's and shows main processing stats in a table format. By default does not show \"off-target\" clonosets -  those having less than 1% (default, may be overriden) of reads for the sample_id. For example, you have sequenced TRB sample, but there is found 0.5% (by read count)  of TRA chains for the same sample_id, then the clonoset will not be shown in the table. You can specify <code>show_offtarget=True</code> to display all found chains in the table or  outherwise set a higher value for <code>off_target_chain_threshold</code> (<code>0.01</code> by default).</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str or list</code> <p>folder or list of folders in which to look for clonosets and processing stats</p> required <code>show_offtarget</code> <code>bool</code> <p>add offtarget chains to the stats</p> <code>False</code> <code>off_target_chain_threshold</code> <code>float</code> <p>threshold for off-target chains</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>dataframe, containing <code>sample_id</code>, <code>extracted_chain</code> and  different processing stats columns. There may be several rows with the same  <code>sample_id</code>, with each found <code>extracted_chain</code></p> Source code in <code>repseq/mixcr.py</code> <pre><code>def get_processing_table(folder, show_offtarget=False, off_target_chain_threshold=0.01):\n    \"\"\"\n    Searches for clonosets in the the folder, extracts their sample_id's and shows main\n    processing stats in a table format. By default does not show \"off-target\" clonosets - \n    those having less than 1% (default, may be overriden) of reads for the sample_id.\n    For example, you have sequenced TRB sample, but there is found 0.5% (by read count) \n    of TRA chains for the same sample_id, then the clonoset will not be shown in the table.\n    You can specify `show_offtarget=True` to display all found chains in the table or \n    outherwise set a higher value for `off_target_chain_threshold` (`0.01` by default).\n\n    Args:\n        folder (str or list): folder or list of folders in which to look for clonosets and\n            processing stats\n        show_offtarget (bool): add offtarget chains to the stats\n        off_target_chain_threshold (float): threshold for off-target chains\n\n    Returns:\n        df (pd.DataFrame): dataframe, containing `sample_id`, `extracted_chain` and \n            different processing stats columns. There may be several rows with the same \n            `sample_id`, with each found `extracted_chain`\n    \"\"\"\n\n    if isinstance(folder, list):\n        tables = []\n        for f in folder:\n            table = get_processing_table(f, show_offtarget=show_offtarget)\n            tables.append(table)\n        return pd.concat(tables).sort_values(by=\"sample_id\").reset_index(drop=True)\n\n    results = []\n    clonosets = find_all_exported_clonosets_in_folder(folder, chain=None)\n\n    for i, r in clonosets.iterrows():\n        sample_id = r[\"sample_id\"]\n        chain = r[\"chain\"]\n        align_report = read_json_report(sample_id, folder, \"align\")\n\n        try:\n            refine_report = read_json_report(sample_id, folder, \"refine\")\n            umi = True\n        except FileNotFoundError:\n            umi = False\n\n        assemble_report = read_json_report(sample_id, folder, \"assemble\")\n\n        # print(sample_id, chain)\n        clonoset = read_clonoset(r.filename)\n        clonoset_f = filter_nonfunctional_clones(clonoset)\n\n        # align report\n        Rt=align_report[\"totalReadsProcessed\"]\n        Ru=align_report[\"totalReadsProcessed\"]-align_report[\"notAlignedReasons\"][\"NoBarcode\"]\n        Ru_pc = round(Ru/Rt*100, 2)\n        Ra=align_report[\"aligned\"]\n        Ra_pc = round(Ra/Rt*100, 2)\n        Roa = align_report[\"overlappedAligned\"]\n        Roa_pc = round(Roa/Ra*100, 2)\n\n        if umi:\n        #Ra2=refine_report[\"correctionReport\"][\"inputRecords\"] ##### differs from Ra, but D.Bolotin did not explain why\n\n            UMIa=refine_report[\"correctionReport\"][\"steps\"][0][\"inputDiversity\"]\n            UMIc=refine_report[\"correctionReport\"][\"steps\"][0][\"outputDiversity\"]\n            try:\n                UMIf=refine_report[\"correctionReport\"][\"filterReport\"][\"numberOfGroupsAccepted\"]\n            except TypeError:\n                UMIf=UMIc\n            Rf=refine_report[\"correctionReport\"][\"outputRecords\"]\n            try:\n                overseq_threshold = int(refine_report[\"correctionReport\"][\"filterReport\"][\"operatorReports\"][0][\"operatorReport\"][\"threshold\"])\n            except TypeError:\n                overseq_threshold = None\n            reads_per_umi = round(Rf/UMIf, 2)\n        else:\n            UMIa = np.nan\n            UMIc = np.nan\n            UMIf = np.nan\n            Rf = np.nan\n            overseq_threshold = np.nan\n            reads_per_umi = np.nan\n\n        Ct=assemble_report[\"clones\"]\n        Rcl=assemble_report[\"readsInClones\"]\n\n        Ctc=len(clonoset)\n        Rclc=int(clonoset.readCount.sum())\n\n        Cfunc=len(clonoset_f)\n        Rfunc=int(clonoset_f.readCount.sum())\n        if umi:\n            UMIcl=clonoset.uniqueMoleculeCount.sum()\n            UMIfunc=clonoset_f.uniqueMoleculeCount.sum()\n        else:\n            UMIcl=np.nan\n            UMIfunc=np.nan\n        if umi and overseq_threshold is None:\n            reads_per_umi = round(Rclc/UMIcl, 2)\n\n        results.append([sample_id, chain, Rt, Ru_pc, Ra_pc, Roa_pc, UMIa, UMIc, overseq_threshold, Rf, UMIf, reads_per_umi, Ct, Rcl, Ctc, Rclc, Cfunc, Rfunc, UMIcl, UMIfunc])\n    result_df = pd.DataFrame(results, columns=[\"sample_id\", \"extracted_chain\", \"reads_total\", \"reads_with_umi_pc\", \"reads_aligned_pc\", \"reads_overlapped_aln_pc\",\n                                               \"total_umi\", \"umi_after_correction\", \"overseq_threshold\", \"reads_after_filter\", \"umi_after_filter\",\n                                               \"reads_per_umi\", \"clones_total\", \"reads_in_clones_total\", \"clones\", \"reads_in_clones\", \"clones_func\", \"reads_in_func_clones\", \"umi_in_clones\", \"umi_in_func_clones\"])\n    if not show_offtarget:\n        result_df = result_df.loc[result_df.reads_in_clones/result_df.reads_in_clones_total &gt; off_target_chain_threshold]\n    return result_df.sort_values(by=\"sample_id\").reset_index(drop=True)\n</code></pre>"},{"location":"mixcr/#show_report_images","title":"show_report_images","text":"<p>This function displays QC images <code>alignQc.svg</code> and <code>chainsQc.svg</code> in Jupyter Notebook. This pictures may be generated by <code>mixcr4_reports</code> function. In case there are no <code>.svg</code> images, the <code>.png</code> images are shown.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>folder in which to look for QC images.</p> required <p>Returns:</p> Type Description <p>None</p> Source code in <code>repseq/mixcr.py</code> <pre><code>def show_report_images(folder):\n    \"\"\"\n    This function displays QC images `alignQc.svg` and `chainsQc.svg` in Jupyter Notebook.\n    This pictures may be generated by `mixcr4_reports` function.\n    In case there are no `.svg` images, the `.png` images are shown.\n\n    Args:\n        folder (str): folder in which to look for QC images.\n\n    Returns:\n        None\n\n    \"\"\"\n\n    svg_align_filename = os.path.join(folder, \"alignQc.svg\")\n    svg_chain_filename = os.path.join(folder, \"chainsQc.svg\")\n    png_align_filename = os.path.join(folder, \"alignQc.png\")\n    png_chain_filename = os.path.join(folder, \"chainsQc.png\")\n\n    if os.path.exists(svg_align_filename):\n        print(svg_align_filename)\n        display(SVG(filename=svg_align_filename))\n    elif os.path.exists(png_align_filename):\n        print(png_align_filename)\n        display(Image(filename=png_align_filename))\n    else:\n        print(\"No alignQc image found (svg or png)\")\n\n    if os.path.exists(svg_chain_filename):\n        print(svg_chain_filename)\n        display(SVG(filename=svg_chain_filename))\n    elif os.path.exists(png_chain_filename):\n        print(png_chain_filename)\n        display(Image(filename=png_chain_filename))\n    else:\n        print(\"No chainQc image found (svg or png)\")\n</code></pre>"},{"location":"page2/","title":"Page 2","text":""},{"location":"page2/#code-annotation-examples","title":"Code annotation examples","text":""},{"location":"page2/#code-blocks","title":"Code blocks","text":"<p>Some <code>code</code> goes here</p>"},{"location":"page2/#plain-code-blocks","title":"Plain code blocks","text":"<pre><code>def read_json_report(sample_id, folder, report_type):\n    filename = os.path.join(folder, f\"{sample_id}.{report_type}.report.json\")\n    with open(filename) as data_file:    \n        for jsonObj in data_file:\n            report = json.loads(jsonObj)\n    return report\n// some comment\n</code></pre>"},{"location":"page2/#code-for-a-specific-language","title":"Code for a specific language","text":"<p>Some more code with the <code>py</code> at the start</p> <pre><code>import sys\nREPSEQ_PATH = '/home/mmyshkin/soft/repseq'\nsys.path.append(REPSEQ_PATH)\nfrom repseq import slurm\nfrom repseq import io\nfrom repseq import common_functions as cf\nfrom repseq import clonosets as cl\nfrom repseq import clustering\nfrom repseq import mixcr as mx\nfrom repseq import segment_usage as su\nfrom repseq import stats\n</code></pre>"},{"location":"page2/#code-with-a-title","title":"Code with a title","text":"import useful packages<pre><code>import os\nimport pandas as pd\nfrom IPython.display import Image, display\nimport json\nimport re\nimport math\nimport random\nimport numpy as np\n</code></pre>"},{"location":"page2/#add-line-numbers","title":"Add line numbers","text":"<pre><code>def shannon_wiener(list_of_numbers):\n    list_of_numbers = list(list_of_numbers)\n    total_size = sum(list_of_numbers)\n    freqs = [s/total_size for s in list_of_numbers]\n    diversity = len(list_of_numbers)\n    sw = -sum([f*np.log(f) for f in freqs])\n    sw_norm = sw/np.log(diversity)\n    return sw, sw_norm, diversity\n</code></pre>"},{"location":"page2/#highlighting-lines","title":"Highlighting lines","text":"<pre><code>def shannon_wiener(list_of_numbers):\n    list_of_numbers = list(list_of_numbers)\n    total_size = sum(list_of_numbers)\n    freqs = [s/total_size for s in list_of_numbers]\n    diversity = len(list_of_numbers)\n    sw = -sum([f*np.log(f) for f in freqs])\n    sw_norm = sw/np.log(diversity)\n    return sw, sw_norm, diversity\n</code></pre>"},{"location":"page2/#icons-and-emojis","title":"Icons and Emojis","text":""},{"location":"page2/#try-to-show-all-the-functions-of-a-module","title":"Try to show all the functions of a module","text":""},{"location":"page2/#intersections.find_intersecting_clonotypes","title":"<code>find_intersecting_clonotypes(clonosets_df, cl_filter=None, overlap_type='aaV', mismatches=0, metric='F2', clonosets_df2=None, cl_filter2=None)</code>","text":"<p>Calculating overlap distances between multiple repseq samples using F2 of F metrics The result of this function may be used for heatmap+clusterization of samples or for MDS plots</p> <p>Parameters:</p> Name Type Description Default <code>clonosets_df</code> <code>DataFrame</code> <p>contains three columns - <code>sample_id</code> and <code>filename</code> columns, filename - full path to clonoset file. Clonoset file may be of MiXCR3/MiXCR4 or VDJtools format sample_id's should be all unique in this DF</p> required <code>overlap_type</code> <code>str</code> <p>possible values are <code>aa</code>, <code>aaV</code>, <code>aaVJ</code>, <code>nt</code>, <code>ntV</code>, <code>ntVJ</code>. aa/nt define which CDR3 sequence to use (amino acid or nucleotide). V/J in the overlap_type define whether to check V or J segments to decide if clonotypes are equal</p> <code>'aaV'</code> <code>mismatches</code> <code>int</code> <p>The permissible number of single-letter mismatches in clonotypes sequences  for them to be treated similar, i.e. hamming distance.</p> <code>0</code> <code>by_umi</code> <code>bool</code> <p>set =True for MiXCR4 clonosets to select count/frequency of clonotypes  in UMI's if they exist in implemented protocol</p> required <code>metric</code> <code>str</code> <p>possible values - <code>F</code>, <code>F2</code> or <code>C</code>. Default <code>F2</code>. <code>F2</code> - sum of sqrt of product of  similar clonotype frequencies in two clonosets. <code>F</code> - sqrt of the sum of frequency products. <code>C</code> - total frequency of clonotypes in <code>sample1</code>, that are similar to clonotypes in <code>sample2</code></p> <code>'F2'</code> <code>only_functional</code> <code>bool</code> <p>use only functional clonotypes (do not contain stop codons or frameshifts in CDR3 sequences: * or _ symbol in CDR3aa sequence). The frequences are recounted to 1 after filtering of non-functional clonotypes</p> required <p>Important: similar clonotypes by <code>overlap_type</code> in one particular clonoset are NOT combined into one and are treated as different clonotypes.</p> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>dataframe with following columns: <code>clone</code>, <code>sample1_count</code>, <code>sample2_count</code>, <code>sample1</code>, <code>sample2</code>, <code>pair</code>.  <code>clone</code> - is tuple, containing sequence (aa or nt), plus V or J if they are required by the metric count columns contain freq/count of the clone in sample pair column is made for easy separation of possibly huge DataFrame into overlapping pairs</p> Source code in <code>repseq/intersections.py</code> <pre><code>def find_intersecting_clonotypes(clonosets_df, cl_filter=None, overlap_type=\"aaV\", mismatches=0, metric=\"F2\", clonosets_df2=None, cl_filter2=None):\n    \"\"\"\n    Calculating overlap distances between multiple repseq samples using F2 of F metrics\n    The result of this function may be used for heatmap+clusterization of samples or for MDS plots\n\n    Args:\n        clonosets_df (pd.DataFrame): contains three columns - `sample_id` and `filename` columns,\n            filename - full path to clonoset file. Clonoset file may be of MiXCR3/MiXCR4 or VDJtools format\n            sample_id's should be all unique in this DF\n        overlap_type (str): possible values are `aa`, `aaV`, `aaVJ`, `nt`, `ntV`, `ntVJ`. aa/nt define which CDR3 sequence\n            to use (amino acid or nucleotide). V/J in the overlap_type define whether to check V or J segments\n            to decide if clonotypes are equal\n        mismatches (int): The permissible number of single-letter mismatches in clonotypes sequences \n            for them to be treated similar, i.e. hamming distance.\n        by_umi (bool): set =True for MiXCR4 clonosets to select count/frequency of clonotypes \n            in UMI's if they exist in implemented protocol\n        metric (str): possible values - `F`, `F2` or `C`. Default `F2`. `F2` - sum of sqrt of product of \n            similar clonotype frequencies in two clonosets. `F` - sqrt of the sum of frequency products.\n            `C` - total frequency of clonotypes in `sample1`, that are similar to clonotypes in `sample2`\n        only_functional (bool): use only functional clonotypes (do not contain stop codons or\n            frameshifts in CDR3 sequences: * or _ symbol in CDR3aa sequence). The frequences are recounted to\n            1 after filtering of non-functional clonotypes\n\n    Important: similar clonotypes by `overlap_type` in one particular clonoset are NOT combined into one\n    and are treated as different clonotypes.\n\n    Returns:\n        df (pd.DataFrame): dataframe with following columns: `clone`, `sample1_count`, `sample2_count`, `sample1`, `sample2`, `pair`. \n            `clone` - is tuple, containing sequence (aa or nt), plus V or J if they are required by the metric\n            count columns contain freq/count of the clone in sample\n            pair column is made for easy separation of possibly huge DataFrame into overlapping pairs\n    \"\"\"\n\n\n    print(\"Intersecting clones in clonosets\\n\"+\"-\"*50)\n    aa, check_v, check_j = overlap_type_to_flags(overlap_type)\n    print(f\"Overlap type: {overlap_type}\")\n\n    clonoset_lists, samples_total, two_dataframes, sample_list, sample_list2 = prepare_clonotypes_dfs_for_intersections(clonosets_df, clonosets_df2,\n                                                                                                                        cl_filter, cl_filter2,\n                                                                                                                        overlap_type, strict=not bool(mismatches))\n\n    # generating a set of tasks\n\n    tasks = []\n\n    if two_dataframes:\n        for sample1 in sample_list:\n            for sample2 in sample_list2:\n                tasks.append((sample1, sample2, clonoset_lists, check_v, check_j, mismatches))        \n    else:\n        for i in range(samples_total):\n            for j in range(samples_total):\n                sample1 = sample_list[i]\n                sample2 = sample_list[j]\n                if sample1 != sample2:\n                    tasks.append((sample1, sample2, clonoset_lists, check_v, check_j, mismatches))\n\n\n    # run calculation in parallel\n    result_list = run_parallel_calculation(find_overlapping_clones_in_two_clone_dicts, tasks, \"Intersecting clonosets\", object_name=\"pairs\")\n\n    return pd.concat(result_list).reset_index(drop=True)\n</code></pre>"},{"location":"page2/#intersections.intersect_clones_in_samples_batch","title":"<code>intersect_clones_in_samples_batch(clonosets_df, cl_filter=None, overlap_type='aaV', by_freq=True, clonosets_df2=None, cl_filter2=None)</code>","text":"<p>Calculating frequencies of intersecting clonotypes between multiple repseq samples. The result of this function may be used for scatterplots of frequencies/counts of  overlapping clonotypes</p> <p>Parameters:</p> Name Type Description Default <code>clonosets_df</code> <code>DataFrame</code> <p>contains three columns - <code>sample_id</code> and <code>filename</code> columns, <code>filename</code> - full path to clonoset file. Clonoset file may be of MiXCR3/MiXCR4 or VDJtools format sample_id's should be all unique in this DF</p> required <code>overlap_type</code> <code>str</code> <p>possible values are <code>aa</code>, <code>aaV</code>, <code>aaVJ</code>, <code>nt</code>, <code>ntV</code>, <code>ntVJ</code>. aa/nt define which CDR3 sequence to use (amino acid or nucleotide). V/J in the overlap_type define whether to check V or J segments to decide if clonotypes are equal</p> <code>'aaV'</code> <code>by_umi</code> <code>bool</code> <p>set <code>=True</code> for MiXCR4 clonosets to select count/frequency of clonotypes  in UMI's if they exist in implemented protocol</p> required <code>by_freq</code> <code>bool</code> <p>default is <code>True</code> - this means that the intersect metric is frequency of clonotype,  but not its count</p> <code>True</code> <code>only_functional</code> <code>bool</code> <p>use only functional clonotypes (do not contain stop codons or frameshifts in CDR3 sequences: * or _ symbol in CDR3aa sequence). The frequences are recounted to 1 after filtering of non-functional clonotypes</p> required <p>Important: when using particular overlap type, similar clonotypes in one particular clonoset are combined into one with summation of counts/frequencies.</p> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>dataframe with following columns: <code>clone</code>, <code>sample1_count</code>, <code>sample2_count</code>, <code>sample1</code>, <code>sample2</code>, <code>pair</code> clone - is tuple, containing sequence (aa or nt), plus V or J if they are required by the metric count columns contain freq/count of the clone in sample pair column is made for easy separation of possibly huge DataFrame into overlapping pairs</p> Source code in <code>repseq/intersections.py</code> <pre><code>def intersect_clones_in_samples_batch(clonosets_df, cl_filter=None, overlap_type=\"aaV\", by_freq=True, clonosets_df2=None, cl_filter2=None):\n    \"\"\"\n    Calculating frequencies of intersecting clonotypes between multiple repseq samples.\n    The result of this function may be used for scatterplots of frequencies/counts of \n    overlapping clonotypes\n\n    Args:\n        clonosets_df (pd.DataFrame): contains three columns - `sample_id` and `filename` columns,\n            `filename` - full path to clonoset file. Clonoset file may be of MiXCR3/MiXCR4 or VDJtools format\n            sample_id's should be all unique in this DF\n        overlap_type (str): possible values are `aa`, `aaV`, `aaVJ`, `nt`, `ntV`, `ntVJ`. aa/nt define which CDR3 sequence\n            to use (amino acid or nucleotide). V/J in the overlap_type define whether to check V or J segments\n            to decide if clonotypes are equal\n        by_umi (bool): set `=True` for MiXCR4 clonosets to select count/frequency of clonotypes \n            in UMI's if they exist in implemented protocol\n        by_freq (bool): default is `True` - this means that the intersect metric is frequency of clonotype, \n            but not its count\n        only_functional (bool): use only functional clonotypes (do not contain stop codons or\n            frameshifts in CDR3 sequences: * or _ symbol in CDR3aa sequence). The frequences are recounted to\n            1 after filtering of non-functional clonotypes\n\n    Important: when using particular overlap type, similar clonotypes in one particular clonoset are\n    combined into one with summation of counts/frequencies.\n\n    Returns:\n        df (pd.DataFrame): dataframe with following columns: `clone`, `sample1_count`, `sample2_count`, `sample1`, `sample2`, `pair`\n            clone - is tuple, containing sequence (aa or nt), plus V or J if they are required by the metric\n            count columns contain freq/count of the clone in sample\n            pair column is made for easy separation of possibly huge DataFrame into overlapping pairs\n    \"\"\"\n\n\n    print(\"Intersecting clones in clonosets\\n\"+\"-\"*50)\n    print(f\"Overlap type: {overlap_type}\")\n\n    clonoset_lists, samples_total, two_dataframes, sample_list, sample_list2 = prepare_clonotypes_dfs_for_intersections(clonosets_df, clonosets_df2,\n                                                                                                                        cl_filter, cl_filter2,\n                                                                                                                        overlap_type, by_freq=by_freq,\n                                                                                                                        strict=True)\n    # generating a set of tasks\n\n    tasks = []\n\n    if two_dataframes:\n        for sample1 in sample_list:\n            for sample2 in sample_list2:\n                tasks.append((sample1, sample2, clonoset_lists))\n    else:\n        for i in range(samples_total):\n            sample1 = sample_list[i]\n            for j in range(samples_total-i-1):\n                sample2 = sample_list[j+i+1]\n                tasks.append((sample1, sample2, clonoset_lists))\n\n    results = run_parallel_calculation(intersect_two_clone_dicts, tasks, \"Intersecting clonosets\", object_name=\"pairs\")\n\n    # df = pd.concat(results).index.set_names()\n    df = pd.concat(results).reset_index(drop=True)\n    df = split_tuple_clone_column(df, overlap_type)\n\n    return df\n</code></pre>"},{"location":"page2/#intersections.overlap_distances","title":"<code>overlap_distances(clonosets_df, cl_filter=None, overlap_type='aaV', mismatches=0, metric='F2', clonosets_df2=None, cl_filter2=None)</code>","text":"<p>Calculating overlap distances between multiple repseq samples using F2 of F metrics The result of this function may be used for heatmap+clusterization of samples or for MDS plots</p> <p>Parameters:</p> Name Type Description Default <code>clonosets_df</code> <code>DataFrame</code> <p>contains three columns - <code>sample_id</code> and <code>filename</code> columns, filename - full path to clonoset file. Clonoset file may be of MiXCR3/MiXCR4 or VDJtools format sample_id's should be all unique in this DF</p> required <code>overlap_type</code> <code>str</code> <p>possible values are <code>aa</code>, <code>aaV</code>, <code>aaVJ</code>, <code>nt</code>, <code>ntV</code>, <code>ntVJ</code>. aa/nt define which CDR3 sequence to use (amino acid or nucleotide). V/J in the overlap_type define whether to check V or J segments to decide if clonotypes are equal</p> <code>'aaV'</code> <code>mismatches</code> <code>int</code> <p>The permissible number of single-letter mismatches in clonotypes sequences  for them to be treated similar, i.e. hamming distance.</p> <code>0</code> <code>by_umi</code> <code>bool</code> <p>set =True for MiXCR4 clonosets to select count/frequency of clonotypes  in UMI's if they exist in implemented protocol</p> required <code>metric</code> <code>str</code> <p>possible values - <code>F</code>, <code>F2</code> or <code>C</code>. Default <code>F2</code>. <code>F2</code> - sum of sqrt of product of  similar clonotype frequencies in two clonosets. <code>F</code> - sqrt of the sum of frequency products. <code>C</code> - total frequency of clonotypes in <code>sample1</code>, that are similar to clonotypes in <code>sample2</code></p> <code>'F2'</code> <code>only_functional</code> <code>bool</code> <p>use only functional clonotypes (do not contain stop codons or frameshifts in CDR3 sequences: * or _ symbol in CDR3aa sequence). The frequences are recounted to 1 after filtering of non-functional clonotypes</p> required similar clonotypes by <code>overlap_type</code> in one particular clonoset will be combined into one <p>clonotype with sum for count.</p> <p>Returns:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>dataframe with following columns: <code>clone</code>, <code>sample1_count</code>, <code>sample2_count</code>, <code>sample1</code>, <code>sample2</code>, <code>pair</code>.  <code>clone</code> - is tuple, containing sequence (aa or nt), plus V or J if they are required by the metric count columns contain freq/count of the clone in sample pair column is made for easy separation of possibly huge DataFrame into overlapping pairs</p> Source code in <code>repseq/intersections.py</code> <pre><code>def overlap_distances(clonosets_df, cl_filter=None, overlap_type=\"aaV\", mismatches=0, metric=\"F2\", clonosets_df2=None, cl_filter2=None):\n    \"\"\"\n    Calculating overlap distances between multiple repseq samples using F2 of F metrics\n    The result of this function may be used for heatmap+clusterization of samples or for MDS plots\n\n    Args:\n        clonosets_df (pd.DataFrame): contains three columns - `sample_id` and `filename` columns,\n            filename - full path to clonoset file. Clonoset file may be of MiXCR3/MiXCR4 or VDJtools format\n            sample_id's should be all unique in this DF\n        overlap_type (str): possible values are `aa`, `aaV`, `aaVJ`, `nt`, `ntV`, `ntVJ`. aa/nt define which CDR3 sequence\n            to use (amino acid or nucleotide). V/J in the overlap_type define whether to check V or J segments\n            to decide if clonotypes are equal\n        mismatches (int): The permissible number of single-letter mismatches in clonotypes sequences \n            for them to be treated similar, i.e. hamming distance.\n        by_umi (bool): set =True for MiXCR4 clonosets to select count/frequency of clonotypes \n            in UMI's if they exist in implemented protocol\n        metric (str): possible values - `F`, `F2` or `C`. Default `F2`. `F2` - sum of sqrt of product of \n            similar clonotype frequencies in two clonosets. `F` - sqrt of the sum of frequency products.\n            `C` - total frequency of clonotypes in `sample1`, that are similar to clonotypes in `sample2`\n        only_functional (bool): use only functional clonotypes (do not contain stop codons or\n            frameshifts in CDR3 sequences: * or _ symbol in CDR3aa sequence). The frequences are recounted to\n            1 after filtering of non-functional clonotypes\n\n    Important: similar clonotypes by `overlap_type` in one particular clonoset will be combined into one\n        clonotype with sum for count.\n\n    Returns:\n        df (pd.DataFrame): dataframe with following columns: `clone`, `sample1_count`, `sample2_count`, `sample1`, `sample2`, `pair`. \n            `clone` - is tuple, containing sequence (aa or nt), plus V or J if they are required by the metric\n            count columns contain freq/count of the clone in sample\n            pair column is made for easy separation of possibly huge DataFrame into overlapping pairs\n    \"\"\"\n\n\n    print(\"Intersecting clones in clonosets\\n\"+\"-\"*50)\n    aa, check_v, check_j = overlap_type_to_flags(overlap_type)\n    print(f\"Overlap type: {overlap_type}\")\n\n    metric = metric.upper()\n    metrics = [\"F\", \"F2\", \"C\", \"BC\", \"J\", \"JSD\"]\n    mismatch_metrics = [\"F\", \"C\"]\n    non_symmetry_metrics = [\"C\"]\n    frequency_metrics = [\"F\", \"F2\", \"C\"]\n\n\n    if metric not in metrics:\n        raise ValueError(f\"Metric {metric} is not supported. Possible values: {', '.join(metrics)}\")\n\n    if mismatches and metric not in mismatch_metrics:\n        raise ValueError(f\"Metric {metric} does not allow mismatches. Mismatches only possible for: {', '.join(mismatch_metrics)}\")\n\n    by_freq = metric in frequency_metrics\n\n    clonoset_lists, samples_total, two_dataframes, sample_list, sample_list2 = prepare_clonotypes_dfs_for_intersections(clonosets_df, clonosets_df2,\n                                                                                                                        cl_filter, cl_filter2,\n                                                                                                                        overlap_type, by_freq=by_freq)\n\n    # generating a set of tasks\n\n    tasks = []\n\n    if two_dataframes:\n        for sample1 in sample_list:\n            for sample2 in sample_list2:\n                tasks.append((sample1, sample2, clonoset_lists, mismatches, metric))        \n    else:\n        if metric not in non_symmetry_metrics and not two_dataframes:\n            for i in range(samples_total):\n                sample1 = sample_list[i]\n                for j in range(samples_total-i-1):\n                    sample2 = sample_list[j+i+1]\n                    tasks.append((sample1, sample2, clonoset_lists, mismatches, metric))\n                if metric == \"F2\":\n                    tasks.append((sample1, sample1, clonoset_lists, mismatches, metric))\n        else:\n            for i in range(samples_total):\n                for j in range(samples_total):\n                    sample1 = sample_list[i]\n                    sample2 = sample_list[j]\n                    if sample1 != sample2:\n                        tasks.append((sample1, sample2, clonoset_lists, mismatches, metric))\n\n\n    # run calculation in parallel\n    result_list = run_parallel_calculation(overlap_metric_two_clone_dicts, tasks, \"Intersecting clonosets\", object_name=\"pairs\")\n\n    if not two_dataframes and metric != \"C\":\n        result_list = result_list + [(result[1], result[0], result[2]) for result in result_list]\n    overlap_df = pd.DataFrame(result_list, columns=[\"sample1\", \"sample2\", metric.lower()]).pivot_table(index=\"sample1\", columns=[\"sample2\"], values=metric.lower()).reset_index().set_index(\"sample1\").fillna(1)\n    return overlap_df\n</code></pre>"},{"location":"page2/#intersections.prepare_clonotypes_dfs_for_intersections","title":"<code>prepare_clonotypes_dfs_for_intersections(clonosets_df, clonosets_df2, cl_filter, cl_filter2, overlap_type, by_freq=True, strict=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>clonosets_df</code> <code>DataFrame</code> <p>description</p> required <code>clonosets_df2</code> <code>DataFrame</code> <p>description</p> required <code>cl_filter</code> <code>Filter</code> <p>description</p> required <code>cl_filter2</code> <code>Filter</code> <p>description</p> required <code>overlap_type</code> <code>str</code> <p>description</p> required <code>by_freq</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>description</p> <code>ValueError</code> <p>description</p> <p>Returns:</p> Name Type Description <code>clonoset_lists</code> <code>dict</code> <p>dict of </p> <code>samples_total</code> <code>int</code> <code>two_dataframes</code> <code>bool</code> <code>sample_list</code> <code>list</code> <code>sample_list2</code> <code>list</code> Source code in <code>repseq/intersections.py</code> <pre><code>def prepare_clonotypes_dfs_for_intersections(clonosets_df, clonosets_df2, cl_filter, cl_filter2, overlap_type, by_freq=True, strict=False):\n    \"\"\"\n    Args:\n        clonosets_df (pd.DataFrame): _description_\n        clonosets_df2 (pd.DataFrame): _description_\n        cl_filter (Filter): _description_\n        cl_filter2 (Filter): _description_\n        overlap_type (str): _description_\n        by_freq (bool, optional): _description_. Defaults to True.\n\n    Raises:\n        ValueError: _description_\n        ValueError: _description_\n\n    Returns:\n        clonoset_lists (dict): dict of \n        samples_total (int): \n        two_dataframes (bool):\n        sample_list (list):\n        sample_list2 (list):\n    \"\"\"\n    # output:\n    ### clonoset_lists\n\n    if len(clonosets_df.sample_id.unique()) &lt; len(clonosets_df):\n        raise ValueError(\"Input clonosets in DataFrame have non-unique sample_id's\")\n    clonosets_df_1 = clonosets_df[[\"sample_id\", \"filename\"]]\n    two_dataframes = False\n    if isinstance(clonosets_df2, pd.DataFrame):\n        two_dataframes = True\n        if len(clonosets_df2.sample_id.unique()) &lt; len(clonosets_df2):\n            raise ValueError(\"Input clonosets in DataFrame2 have non-unique sample_id's\")\n        clonosets_df_2 = clonosets_df2[[\"sample_id\", \"filename\"]]\n        intersecting_sample_ids = set(clonosets_df2.sample_id.unique()).intersection(set(clonosets_df.sample_id.unique()))\n        if len(intersecting_sample_ids) &gt; 0 and cl_filter2 is not None:\n            print(\"WARNING! Some samples have the same sample_id in two sample_df's. The second filter will be applied to common samples\")\n\n\n    # converting clonosets to compact lists of clonotypes separated by CDR3 lengths to dictionary based on overlap type and count/freq/umi\n    clonoset_lists = convert_clonosets_to_compact_dicts(clonosets_df_1, cl_filter=cl_filter,\n                                                        overlap_type=overlap_type, by_freq=by_freq, strict=strict)\n    if two_dataframes:\n        if cl_filter2 is None:\n            cl_filter2 = cl_filter\n        clonoset_lists_2 = convert_clonosets_to_compact_dicts(clonosets_df_2, cl_filter=cl_filter2,\n                                                        overlap_type=overlap_type, by_freq=by_freq, strict=strict)\n        clonoset_lists.update(clonoset_lists_2)\n\n    samples_total = len(clonosets_df_1)\n    if two_dataframes:\n        samples_total = len(pd.concat([clonosets_df_1, clonosets_df_2]))\n\n    sample_list = list(clonosets_df_1.sort_values(by=\"sample_id\").sample_id)\n    sample_list2 = None\n    if two_dataframes:\n        sample_list2 = list(clonosets_df_2.sort_values(by=\"sample_id\").sample_id)\n\n    return clonoset_lists, samples_total, two_dataframes, sample_list, sample_list2\n</code></pre>"},{"location":"supporting_modules/","title":"IO module","text":"<p>This module contains functions for input-output procedures</p>"},{"location":"supporting_modules/#read_yaml_metadata","title":"read_yaml_metadata","text":"<p>Reads NGSiK metadata from a given folder and converts to <code>pd.DataFrame</code>. By default  it searches for <code>metadata.yaml</code> file in this folder and extracts the table.</p> <p>Parameters:</p> Name Type Description Default <code>folder</code> <code>str</code> <p>path to NGSiK folder</p> required <code>filename</code> <code>str</code> <p>NGSiK metadata filename</p> <code>'metadata.yaml'</code> <p>Returns:</p> Name Type Description <code>sample_df</code> <code>DataFrame</code> <p>extracted DataFrame from metadata</p> Source code in <code>repseq/io.py</code> <pre><code>def read_yaml_metadata(folder, filename=\"metadata.yaml\"):\n\n    \"\"\"\n    Reads NGSiK metadata from a given folder and converts to `pd.DataFrame`. By default \n    it searches for `metadata.yaml` file in this folder and extracts the table.\n\n    Args:\n        folder (str): path to NGSiK folder\n        filename (str): NGSiK metadata filename\n\n    Returns:\n        sample_df (pd.DataFrame): extracted DataFrame from metadata\n\n    \"\"\"\n\n\n    most_important_columns = [\"sample_id\", \"R1\", \"R2\",\"libraryPerson\", \"projectPerson\", \"projectName\", \"species\", \"miNNNPattern\", \"SMPL\", \"mix_id\", \"preset\", \"startingMaterial\", \"libraryType\"]\n    yaml_filename = os.path.join(folder, filename)\n    with open(yaml_filename, \"r\") as stream:\n        try:\n            metadata_dict =yaml.safe_load(stream)\n    #         pd.io.json.json_normalize(metadata_dict, \"file\", \"samples\", errors='ignore')\n        except yaml.YAMLError as exc:\n            print(exc)\n\n    df = pd.json_normalize(metadata_dict)\n    df = df.explode(\"file\")\n    df = pd.concat([df.drop(['file'], axis=1), df['file'].apply(pd.Series)], axis=1)\n    df = df.explode(\"samples\")\n    df = pd.concat([df.drop(['samples'], axis=1), df['samples'].apply(pd.Series)], axis=1)\n    if 'patternGroupValues' in df.columns:\n        df = pd.concat([df.drop(['patternGroupValues'], axis=1), df['patternGroupValues'].apply(pd.Series)], axis=1)\n    df[\"R1\"] = df[\"R1\"].apply(lambda x: os.path.join(folder, x))\n    df[\"R2\"] = df[\"R2\"].apply(lambda x: os.path.join(folder, x))\n    df = df.rename(columns={\"name\": \"sample_id\"})\n\n    for col_name in most_important_columns[::-1]:\n        if col_name in df.columns:\n            first_column = df.pop(col_name) \n            df.insert(0, col_name, first_column)\n\n    return df.reset_index(drop=True)\n</code></pre>"},{"location":"supporting_modules/#read_clonoset","title":"read_clonoset","text":"<p>Reads generic clonoset files.  Easyly reads <code>csv</code>, <code>tsv</code>, <code>txt</code> or <code>gz</code> files. Reads first found file inside <code>zip</code> files. Clonosets should be in tab-separated format: MiXCR (v3 or v4), vdjtools, Bioadaptive</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>path to clonoset file</p> required <p>Returns:</p> Name Type Description <code>clonoset</code> <code>DataFrame</code> <p>DataFrame representation of clonoset in given file. Bioadaptive clonosets are converted to vdjtools-like format.</p> Source code in <code>repseq/io.py</code> <pre><code>def read_clonoset(filename):\n    \"\"\"\n    Reads generic clonoset files. \n    Easyly reads `csv`, `tsv`, `txt` or `gz` files.\n    Reads first found file inside `zip` files.\n    Clonosets should be in tab-separated format: MiXCR (v3 or v4), vdjtools, Bioadaptive\n\n    Args:\n        filename (str): path to clonoset file\n\n    Returns:\n        clonoset (pd.DataFrame): DataFrame representation of clonoset in given file.\n            Bioadaptive clonosets are converted to vdjtools-like format.\n    \"\"\"\n\n\n    file_name, file_extension = os.path.splitext(filename)\n\n    d_types_mixcr = {'cloneId': int, 'readCount': int, 'readFraction': float,\n                    'uniqueUMICount': int, 'uniqueUMIFraction': float,\n                    'uniqueMoleculeCount': int, 'uniqueMoleculeFraction': float,\n                    'cloneCount': int, 'cloneFraction': float,\n                    'targetSequences': str, 'targetQualities': str,\n                    'allVHitsWithScore': str, 'allDHitsWithScore': str,\n                    'allJHitsWithScore': str, 'allCHitsWithScore': str,\n                    'allVAlignments': str, 'allDAlignments': str,\n                    'allJAlignments': str, 'allCAlignments': str,\n                    'nSeqFR1': str, 'minQualFR1': str,\n                    'nSeqCDR1': str, 'minQualCDR1': str,\n                    'nSeqFR2': str, 'minQualFR2': str,\n                    'nSeqCDR2': str, 'minQualCDR2': str,\n                    'nSeqFR3': str, 'minQualFR3': str,\n                    'nSeqCDR3': str, 'minQualCDR3': str,\n                    'nSeqFR4': str, 'minQualFR4': str,\n                    'aaSeqFR1': str, 'aaSeqCDR1': str,\n                    'aaSeqFR2': str, 'aaSeqCDR2': str,\n                    'aaSeqFR3': str, 'aaSeqCDR3': str,\n                    'aaSeqFR4': str, 'refPoints': str\n                    }\n\n    d_types_vdjtools = {'cdr3aa': str, 'cdr3nt': str,\n                        'v': str, 'd': str, 'j': str,\n                        'CDR3aa': str, 'CDR3nt': str,\n                        'V': str, 'D': str, 'J': str,\n                        'C': str, \"frequency\": float#,\n                        #'count': int, 'freq': float#,\n                        #'VEnd':int, 'DStart':int, 'DEnd':int, \"JStart\":int\n                        }\n\n    d_types_bioadaptive = {'nucleotide': str, 'aminoAcid': str,\n                            'count (templates/reads)': int,\n                            'frequencyCount (%)': float,\n                            'vGeneName': str, 'dGeneName': str,\n                            'jGeneName': str, 'cdr3Length': int,\n                            'n1Index': int,'dIndex': int,\n                            'n2Index': int,'jIndex': int\n                            }\n\n\n    datatypes = {**d_types_mixcr,**d_types_vdjtools, **d_types_bioadaptive}\n    if file_extension == \".zip\":\n        archive = zipfile.ZipFile(filename, 'r')\n        inner_filename = zipfile.ZipFile.namelist(archive)[0]\n        filename = archive.open(inner_filename)\n    clonoset = pd.read_csv(filename, sep=\"\\t\", dtype=datatypes)\n    if 'count (templates/reads)' in clonoset.columns:\n        clonoset = convert_bioadaptive_clonoset(clonoset)\n    return clonoset\n</code></pre>"},{"location":"supporting_modules/#read_json_report","title":"read_json_report","text":"<p>Reads MiXCR4 json reports into a Python mixed data structure. This function takes the last json record, if for example MiXCR adds up several records  to json file (it happens, when the program is rerun several times on the same data). Program also includes cases when Sample-barcodes are used.</p> <p>Parameters:</p> Name Type Description Default <code>sample_id</code> <code>str</code> <p>sample_id used when running the MiXCR program</p> required <code>folder</code> <code>str</code> <p>folder in which the MiXCR output is stored</p> required <code>report_type</code> <code>str</code> <p>align, refine, assemble</p> required <p>Returns:</p> Name Type Description <code>report</code> <code>dict</code> <p>mixed dict/list python structure, representing the json report</p> Source code in <code>repseq/io.py</code> <pre><code>def read_json_report(sample_id, folder, report_type):\n    \"\"\"\n    Reads MiXCR4 json reports into a Python mixed data structure.\n    This function takes the last json record, if for example MiXCR adds up several records \n    to json file (it happens, when the program is rerun several times on the same data).\n    Program also includes cases when Sample-barcodes are used.\n\n    Args:\n        sample_id (str): sample_id used when running the MiXCR program\n        folder (str): folder in which the MiXCR output is stored\n        report_type (str): align, refine, assemble\n\n    Returns:\n        report (dict): mixed dict/list python structure, representing the json report\n    \"\"\"\n\n\n    filename = os.path.join(folder, f\"{sample_id}.{report_type}.report.json\")\n    if \".\" in sample_id:\n        sample_id2 = \".\".join(sample_id.split(\".\")[:-1])\n        filename2 = os.path.join(folder, f\"{sample_id2}.{report_type}.report.json\")\n        try:\n            report = open_json_report(filename)\n        except FileNotFoundError:\n            report = open_json_report(filename2)\n    else:\n        report = open_json_report(filename)\n    return report\n</code></pre>"}]}